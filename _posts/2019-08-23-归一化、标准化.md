---
layout: post
title:  "归一化、标准化"
date:   2019-08-23 11:44:01 +0800
categories: 人工智能
tag: 深度学习基础
---

* content
{:toc}


****

> **未经许可，严禁任何形式转载**

****

**参考**：

1. [数据标准化 / 归一化 normalization](<https://blog.csdn.net/pipisorry/article/details/52247379>)
2. [为什么要对数据进行归一化处理？](https://www.cnblogs.com/silence-tommy/p/7113498.html)
3. [数据特征标准化和归一化](<https://blog.csdn.net/zwqjoy/article/details/81182102>)

****

# 归一化 Normalization

## 归一化的定义

在机器学习领域中，不同的特征往往具有不同的**量纲和数量级**。当不同特征之间的数值相差较大时，各特征对目标函数的影响是不同的。

因此，为了保证结果的可靠性，需要对原始指标数据进行归一化处理。

> 归一化一般是将数据映射到指定的范围，用于去除不同维度数据的量纲以及量纲单位，**消除奇异样本数据**导致的不良影响。常见的映射范围有 `[0, 1]` 和 `[-1, 1]`。

## 常用归一化方式

### Min-Max 归一化 (最常用)

#### 计算方式

$$
x_{n e w}=\frac{x-x_{\min }}{x_{\max }-x_{\min }}
$$

`Min-Max` 归一化，将使得数据分布于 `[0, 1]` 之间。

#### 缺陷

如果 `max` 和 `min`不稳定，很容易使得归一化结果不稳定，使得后续使用效果也不稳定。实际使用中可以用经验常量来替代 `max` 和 `min`。

### **Log 转换** 

$$
x_{n e w}=\frac{\log _{10} x}{\log _{10} x_{\max }}
$$

### 反余切函数转换

$$
x_{new}=\frac{2 * \arctan x}{\pi}
$$

## 归一化对数据分布的影响

归一化对数据分布的影响如下所示，仅改变了取值范围，不改变分布：

<div style="text-align:center">
<img src="/images/归一化图示.png" width="60%">
</div><br>

## 归一化的作用

### 加快收敛速度

 以房价预测为例，现在根据房间数和房间面积，来预测房价。那么可以得到的公式为：

$$
y=\theta_{1} x_{1}+\theta_{2} x_{2}
$$

**未归一化时**

未归一化时，计算公式如下：

$$
J=\left(3 \theta_{1}+600 \theta_{2}-y_{c o r r e c t}\right)^{2}
$$

其对应的图像如下所示：

<div style="text-align:center">
<img src="/images/未归一化.png" width="50%">
</div><br>

如上图所示，不均匀的数值，将会导致等高线为椭圆形。

> 而**梯度下降时，梯度方向为垂直于等高线的方向**，因此优化走的是 z 字型路线。

所以，数据值不均衡时，轻则导致收敛变慢，重则无法收敛。因而，必须要进行归一化。

**归一化时**

数据归一化之后，损失函数的表达式可以表示为：

$$
J=\left(0.5 \theta_{1}+0.55 \theta_{2}-y_{\text {correct}}\right)^{2}
$$

归一化之后，数据相对均衡，对应的图像如下所示：

<div style="text-align:center">
<img src="/images/归一化后.png" width="50%">
</div><br>

如上图所示，数据归一化后，最优解的寻优过程明显会变得平缓，更容易正确的收敛到最优解。

### 提高模型精度

> 在涉及距离计算的时候，归一化能够明显提升精度。

未进行归一化的时候，不同特征分量对距离计算的影响不同，从而导致精度的损失。而归一化后，将会使得各个特征对结果的贡献相同。

## 适用场合

标准化可以更好地保持样本间距，因为其只对数值进行了缩放，不改变其分布。

我们必须要特征在 `0` 到 `1` 之间，此时就只能用归一化。有种 `svm` 可用来做单分类，里面就需要用到归一化。

# 标准化 Standardization

## 标准化的定义

标准化与归一化类似，都是将数据进行缩放。但是标准化不是缩放到 `[0, 1]` 区间内，而是将数据缩放到某一值附近，使其达到某一标准差。

常用的标准化手段为 `z-score` 标准化。

## z-score 标准化

> `z-score` 标准化将使得数据符合**标准正态分布**，即：均值为 0，标准差为 1。

> 该种标准化方式要求原始数据的分布可以近似为高斯分布，否则效果会变得很糟糕。

### 计算方式

`z-score` 计算方式如下所示：

$$
z=\frac{x_{i}-\mu}{\sigma}
$$

其中，$$\mu$$ 是样本数据的**均值（mean）**，$$ \sigma $$ 是样本数据的**标准差（std）**。

### 证明：z-score 均值 0， 标准差 1

证明：若 $$ X^{*}=\frac{X-E(X)}{\sqrt{D(X)}} $$，则：$$ E\left(X^{*}\right)=0, D\left(X^{*}\right)=1 $$。

证：

$$
\begin{aligned}
E\left(X^{*}\right)&=E\left[\frac{X-E(X)}{\sqrt{D(X)}}\right]=\frac{1}{\sqrt{D(X)}} E[X-E(X)]=0 \\

D\left(X^{*}\right)&=D\left[\frac{X-E(X)}{\sqrt{D(X)}}\right]=\frac{1}{D(X)} D[X-E(X)]=\frac{D(X)}{D(X)}=1
\end{aligned}
$$


###标准化对数据分布的影响

<div style="text-align:center">
<img src="/images/Standarlize 图示.png" width="90%">
</div><br>

如上图所示，为一个散点序列的标准化过程：**原始数据 —> 减去均值 —> 除以标准差**。显而易见，最后变成了一个 `0` 均值，`1` 方差的分布。

 <div style="text-align:center">
<img src="/images/标准化数据分布.png" width="80%">
</div><br>

### 标准化的作用

1. 比较具有不同单位和范围的特征数据
2. `Standardization` 倾向于使得训练过程表现更佳，因为优化问题的数值条件得到了改善。(与归一化类似)

## Batch Normalization

在机器学习中，最常用标准化的地方莫过于神经网络的 **BN 层（Batch Normalization）**，详见《`batch normalization`》。

我们知道数据预处理做标准化可以加速收敛，同理，在神经网络使用标准化也可以**加速收敛**，而且还有如下好处：

1. 具有正则化的效果（`Batch Normalization reglarizes the model`）
2. 提高模型的泛化能力（`Be advantageous to the generalization of network`）
3. 允许更高的学习速率从而加速收敛（`Batch Normalization enables higher learning rates`）

其原理是**利用正则化减少内部相关变量分布的偏移（Reducing Internal Covariate Shift）**，从而**提高了算法的鲁棒性**。

## 面试问题

1. 逻辑回归必须用标准化吗？

   这取决于**逻辑回归是不是用正则**。**如果你不用正则，那么，标准化并不是必须的，如果你用正则，那么标准化是必须的**。

   因为不用正则时，我们的损失函数**只是仅仅**在度量**预测与真实的差距**。

   加上正则后，我们的损失函数除了要度量上面的差距外，还要度量**参数值**是否足够小。而**参数值的大小程度是与特征的数值范围**相关的。

2. 如果不用正则，那么标准化对逻辑回归有什么好处吗 ？

   有好处，进行标准化后，我们得出的参数值的大小可以反应出不同特征对样本 `label` 的**贡献度**，方便我们进行特征筛选。

   如果不做标准化，是不能这样来筛选特征的。

3. 做标准化有什么注意事项吗 ?

   最大的注意事项就是先拆分出 `test` 集，**不要在整个数据集上做标准化**，因为那样会 **将 `test` 集的信息引入到训练集** 中，这是一个非常容易犯的错误！

# 总结

- **归一化（`Normalization`）**：

  数据预处理，将数据限定在特定范围内，**消除量纲对建模的影响**；

- **标准化（`Standardization`）**：

  数据预处理，使数据符合**标准正态分布**；

- **正则化（`Regularization`）**：

  在损失函数中添加惩罚项，**增加建模模糊性**，将建模关注点转移到整体趋势上；