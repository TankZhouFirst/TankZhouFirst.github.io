---
layout: post
title:  "生成模型与判别模型"
date:   2019-08-14 09:28:01 +0800
categories: 人工智能
tag: GANs
---

* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**

****

## 引入

机器学习可以分为监督学习和无监督学习。其中，监督学习方法又可以分为生成方法(`generative approach`)和判别方法(`discriminative approach`)，其对应的模型分别为生成模型(`generative model`)和判别模型(`discriminative model`)。

## 决策函数与条件概率分布

### 决策函数 `Y = f(X)`

你输入一个 `X`，它就输出一个 `Y`，这个 `Y` 与一个阈值比较，根据比较结果判定 `X` 属于哪个类别。例如二分类（`w1` 和 `w2` ）问题，如果 `Y` 大于阈值，`X` 就属于类 `w1`，如果小于阈值就属于类 `w2`。这样就得到了该 `X` 对应的类别了。

### 条件概率分布 `P(Y|X)`

你输入一个 `X`，它通过比较它属于所有类的概率，然后输出概率最大的那个作为该 `X` 对应的类别。例如：如果 $$ P(w1\|X) $$ 大于 $$P(w2\|X)$$，那么我们就认为 `X` 是属于 `w1` 类的。

### 小结

两个模型都可以实现对给定的输入 `X` 预测相应的输出 `Y` 的功能。实际上通过条件概率分布 $$P(Y\|X)$$ 进行预测也是隐含着表达成决策函数 $$Y=f(X)$$ 的形式的。  

而同样，很神奇的一件事是，实际上决策函数 $$Y=f(X)$$ 也是隐含着使用 $$P(Y\|X)$$ 的。因为一般决策函数 $$Y=f(X)$$ 是通过学习算法使你的预测和训练数据之间的误差平方最小化。

而贝叶斯告诉我们，虽然它没有显式的运用贝叶斯或者以某种形式计算概率，但它实际上也是在隐含的输出极大似然假设（`MAP` 假设）。也就是说学习器的任务是在所有假设模型有相等的先验概率条件下，输出极大似然假设。

## 生成方法和生成模型

### 基本概念

**生成模型**：无穷样本 ==> 概率密度模型 = 产生模型 ==> 预测  

生成方法由数据学习联合概率分布 $$P(X,Y)$$，然后求出条件概率分布 $$P(Y\|X) = \frac{P(X,Y)}{P{X}}$$ 作为预测的模型。这样的方法之所以成为生成方法，是因为模型表示了给定输入 `X` 产生输出 `Y` 的生成关系。  

用于随机生成的观察值建模，特别是在给定某些隐藏参数情况下。典型的生成模型有：朴素贝叶斯法、马尔科夫模型、高斯混合模型。这种方法一般建立在统计学和 `Bayes` 理论的基础之上。  

### 生成方法的特点

- 从统计的角度表示数据的分布情况，能够反映同类数据本身的相似度;
- 只关注自己的类本身，不关心到底决策边界在哪。
- 生成方法还原出联合概率分布，而判别方法不能；
- 生成方法的学习收敛速度更快、即当样本容量增加的时候，学到的模型可以更快地收敛于真实模型；
- 当存在隐变量时，仍可以用生成方法学习，此时判别方法不能用。

## 判别方法和判别模型

### 基本概念

**判别模型**：有限样本 ==> 判别函数 = 预测模型 ==> 预测

判别方法由数据直接学习决策函数 $$f(X)$$ 或者条件概率分布 $$P(Y\|X)$$ 作为预测的模型，即判别模型。判别方法关心的是对给定的输入 `X`，应该预测什么样的输出 `Y`。  

典型的判别模型包括：`k` 近邻法、感知机、决策树、逻辑斯蒂回归模型、最大熵模型、支持向量机、`boosting` 方法和条件随机场等。判别模型利用正负例和分类标签，关注在判别模型的边缘分布.


### 判别方法的特点

- 判别方法寻找不同类别之间的最优分类面，反映的是异类数据之间的差异;
- 判别方法利用了训练数据的类别标识信息，直接学习的是条件概率 $$P(Y\|X)$$ 或者决策函数 $$f(X)$$，直接面对预测，往往学习的准确率更高；
- 由于直接学习条件概率 $$P(Y\|X)$$ 或者决策函数 $$f(X)$$，可以对数据进行各种程度上的抽象、定义特征并使用特征，因此可以简化学习问题。
- 缺点是不能反映训练数据本身的特性

## 判别模型和生成模型对比

### **训练时，二者优化准则不同**

- 生成模型优化训练数据的联合分布概率；
- 判别模型优化训练数据的条件分布概率，判别模型与序列标记问题有较好的对应性。

### **对于观察序列的处理不同**

- 生成模型中，观察序列作为模型的一部分；
- 判别模型中，观察序列只作为条件，因此可以针对观察序列设计灵活的特征。

### **训练复杂度不同**

判别模型训练复杂度较高。

### **是否支持无指导训练**

生成模型支持无指导训练。

### **本质区别**  

`discriminative model` 估计的是条件概率分布 `(conditional distribution)`，即 $$p(class\|context)$$；
`generative model` 估计的是联合概率分布 `（joint probability distribution）`
 另外，由生成模型可以得到判别模型，但由判别模型得不到生成模型。

### **通俗解释**  

**判别模型**

是在你生父身高超过 `180` 的已知条件下，预测你身高会不会超过 `180`。如果你生父比 `180` 高，那么你比 `180` 高的概率会增加。但是全世界人身高的概率分布暂时并没有改变。  

**生成模型**

则是随机赐予你一个成年后的最高身高。身高超过 `180` 的概率是多少，这个概率只能依照全世界所有成人的身高的频率分布来决定。

## 对于跟踪算法

由于之前用 `Camshift` 方法做人脸的跟踪，这里看到了有关跟踪算法的说明，特此陈述一下。  

跟踪算法一般来说可以分为两类：基于外观模型的生成模型或者基于外观模型的判别模型。  

**生成模型**：

一般是学习一个代表目标的模型，然后通过它去搜索图像区域，然后最小化重构误差。类似于生成模型描述一个目标，然后就是模式匹配了，在图像中找到和这个模型最匹配的区域，就是目标了。  

**判别模型**：

将跟踪问题看成一个二分类问题，然后找到目标和背景的决策边界。它不管目标是怎么描述的，那只要知道目标和背景的差别在哪，然后你给一个图像，它看它处于边界的那一边，就归为哪一类。