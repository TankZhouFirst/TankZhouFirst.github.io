---
layout: post
title:  "模型的使用"
date:   2019-07-07 22:37:01 +0800
categories: 人工智能
tag: Pytorch
---


* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**


****

# 模型的保存与加载

## 模型查看

```python
# 查看模型结构
print(mpdel)

# 查看详细参数
params = list(model.named_parameters())
for k, v in params:
  # k   参数名称
  # v   参数值

# 查看梯度
print(param.grad)    # 查看梯度
```

## 模型的保存

### 保存模型 + 参数

```python
torch.save(model_object, 'model.pkl')
```

上面代码将会保存所有数据到文件 `"model.pkl"`。

### 仅保存参数

```python
torch.save(model_object.state_dict(), 'params.pth')
```

上面的代码将会保存所有参数到文件 `'params.pth'`。

> 注意这两者是有区别的。前者保存所有数据（模型结构 + 模型参数），下次加载的时候，可以直接 `load` 就能创建模型，并加载参数；
>
> 而后者必须先创建模型，再通过 `load_state_dict` 加载参数。

## 模型的加载

### 基本加载方法

#### 加载所有数据

下面代码将会加载所有数据，即：先自动创建模型，然后加载参数。

必须要注意一点：**模型网络的定义代码必须存在**！

```python
# 必须有定义
class Net(...):
  ...

model = torch.load('model.pkl')
```

#### 加载模型参数

如果先定义好了网络，那么通过网络，就只能加载参数，如下所示：

```python
net = Net()   # 创建模型

# 加载参数
net.load_state_dict(torch.load('params.pth'))

# 从完整数据加载参数
net.load_state_dict(torch.load('params.pkl').state_dict())
```

#### 加载部分层参数

有时候，只需要某一网络中的部分预训练参数，可以使用如下方式加载指定层的参数：

```python
pretrained_dict=torch.load(model_weight)

model_dict=myNet.state_dict()

# 1. filter out unnecessary keys
pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}

# 2. overwrite entries in the existing state dict
model_dict.update(pretrained_dict)
myNet.load_state_dict(model_dict)
```

### pytorch 预设模型

`Pytorch` 提供了一些主流的模型结构，并提供了与训练好的参数。

这些模型的期望输入是 **RGB** 格式的图像的 **mini-batch**，即：$$ (batch_size, 3, H, W) $$，像素值必须在范围 $$[0,1]$$ 间，并且用均值 $$mean=[0.485, 0.456, 0.406]$$ 和方差 $$std=[0.229, 0.224, 0.225]$$ 进行归一化。

下面代码将使用 `pytorch` 预设的 **VGG16** ，其中 **pretrained=True** 表示使用预训练的参数：

```python
import torchvision.models as models

vgg16 = models.vgg16(pretrained=True)
```

### 并行模型与串行模型加载

如果用多 `GPU` 进行并行运行，则其保存的参数会有些许不同。所以，并行保存的参数，加载到非并行模型上时，可能会报错：`KeyError: ‘unexpected key “module.conv1.weight” in state_dict’`。

```python
# 一般模型参数变为并行参数
def _Single2Parallel(self, origin_state):
    """
    将串行的权值参数转换为并行的权值参数
    :param origin_state : 原始串行权值参数
    :return             : 并行的权值参数
    """
  	converted = OrderedDict()
  
    for k, v in origin_state.items():
      name = "module." + k
      converted[name] = v
  
  	return converted

# 并行参数变为一半参数
def _Parallel2Single(self, origin_state):
  	"""
  	将并行的权值参数转换为串行的权值参数
  	:param origin_state : 原始串行权值参数
  	:return             : 并行的权值参数
  	"""
    converted = OrderedDict()
    
    for k, v in origin_state.items():
      name = k[7:]
      converted[name] = v
      
    return converted
```

### 参数 CPU / GPU 之间转移

在加载预训练模型时，最好指定 `map＿location`。因为如果程序之前在 `GPU` 上运行，那么模型就会被存成 `torch.cuda.Tensor`，这样加载时会默认将数据加载至显存。

如果运行该程序的计算机中没有 `GPU`，加载就会报错，故通过指定 `map_location` 将　`Tensor`  默认加载入内存中，待有需要时再移至显存中。

```python
torch.load('tensors.pth')
# 把所有的张量加载到 CPU 中
torch.load('tensors.pth', map_location=lambda storage, loc: storage)
# 把所有的张量加载到 GPU 1 中
torch.load('tensors.pt', map_location=lambda storage, loc: storage.cuda(1))
# 把张量从 GPU 1 移动到 GPU 0
torch.load('tensors.pt', map_location={'cuda:1':'cuda:0'})
```

# 模型的使用

## 模型的训练与推理

需要注意的是，在训练阶段，需要将模型设置为训练状态：

```python
model.train()
```

而在验证测试阶段，需要将模型设置为验证状态：

```python
model.eval()
```

这是因为，模型中 `BatchNorm` 和 `Dropout` 等层，不同状态下运行结果不一样。如果验证模型时，发现明显的欠拟合，可能就是因为没有用 `eval` 导致的。

## 保存与加载 checkpoint

```python
torch.save({
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'loss': loss,
            ...
            }, PATH)
```

```python
model = TheModelClass(*args, **kwargs)
optimizer = TheOptimizerClass(*args, **kwargs)

checkpoint = torch.load(PATH)
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']

model.eval()
# - or -
model.train()
```
