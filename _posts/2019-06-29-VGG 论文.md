---
layout: post
title:  "VGG 论文"
date:   2019-06-29 22:14:01 +0800
categories: 人工智能
tag: 图像分类
---


* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**


****

**参考 :**

- **Paper :** [Very deep convolutional networks for large-scale image recognition](https://arxiv.org/pdf/1409.1556.pdf)
- **Code :** [GitHub](https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py)

****

# 引入

## 问题背景

随着 `CNNs` 的逐渐流行，领域都在积极探索改进 `CNNs` 的方式。

## 本文的主要贡献

本文主要探究了在大尺寸图像识别任务中，网络深度与识别准确度的关系。

最终网络深度达到了 `16~19` 层，相较于时下最先进的网络，性能得到了大幅度改善。最终在 `2014` 年的  `(ILSVRC)` 比赛中，分别获得了 `classification` 和 `localisation`  的第一第二名。

此外，网络还可以泛化到其他数据集。

本文的主要贡献在于：

- 提出用多层 $$3 \times 3$$ 的卷积层来替换大尺寸的卷积核，从而提升网络的深度。
- 使用 $$ 1 \times 1$$ 的卷积核进行各通道的特征融合，以及增加非线性 (这里还未用于 `reduction`)

<div style="text-align:center">
<img src="/images/VGG 结构.png" width="80%"/>
<p>VGG 整体图示</p>
</div><br>


# VGG 网络配置

## 网络架构

### 网络输入

在训练过程中，网络输入尺寸固定为 $$224 \times 224$$ 的 `RGB` 图像，唯一的预处理就是：基于整个训练集计算 `RGB` 的均值，然后每个像素节点上减去该均值。 

### 网络各层结构

#### 卷积层

在这里，网络用 $$ 3 \times 3$$ 的小尺寸卷积核来提取特征，并用 $$1 \times 1$$ 的卷积核来作线性转换（后接非线性层）。卷积运算的步长设置为 `1`，且进行 `padding`，使得卷积前后尺寸不变。

####  池化层  
池化层选取 `max-pooling`，步长为 `2`， 尺寸为 `2 * 2`。 因此，特征图的尺寸变换只发生于池化层。 

#### **全连接层** 

网络最后，接着 `3` 个全连接层（`Fully-Connected layers`）。神经元数目分别为：`4096`，`4096`，`1000`，最后 `1000` 用于 `1000` 分类。最后用一个 `softmax` 层，用于计算类别的概率（约束在 `0~1` 之间，和为 `1`）。

#### **激活函数**  

整个网络使用 `ReLU` 作为非线性激活函数。由于 `Local Response Normalisation
(LRN)` 归一化对网络无益，所以网络未使用。

## 网络配置

本文验证了多种 `VGG` 结构，各个结构只有深度不同，其余配置一样。分别用 `A-E` 表示，如下图所示：

<div style="text-align:center">
<img src="/images/VGG 网络配置.png" width="85%"/>
<p>VGG 不同配置下的网络结构</p>
</div><br>


上图中的各个结构，对应的参数数量如下所示：

<div style="text-align:center">
<img src="/images/VGG 参数数量.png" width="75%"/>
<p>VGG 不同配置下的参数数量</p>
</div><br>


## 一些讨论

### 3 * 3 卷积核的作用

#### 感受野等效

本文没有使用步长为 `2`，尺寸为 `7 * 7` 的卷积核，而是使用步长为 `1`，尺寸为 `3 * 3` 的卷积核。  

实际上，两层 `3 * 3` 的卷积核，其感受野相当于尺寸为 `5 * 5` 的卷积核，三层 `3 * 3` 的卷积核，其感受野相当于尺寸为 `7 * 7` 的卷积层。如下图所示：

<div style="text-align:center">
<img src="/images/3x3 感受野.png" width="40%"/>
<p>感受野等效图示</p>
</div><br>


#### 3 \* 3 卷积核作用

那么，使用 `3 * 3` 卷积核有什么好处呢？

1. 多层卷积层（每个卷积层后都有非线性激活函数），**增加非线性**，提升模型性能。
2. 大幅度减少模型参数数量。 $$7C * 7C = 49C^2$$，而 $$3 * (3C)^2 = 27C^2$$，大幅度减少了参数数量。另外，选取小的 `stride` 可以防止较大的 `stride` 导致细节信息的丢失。

### 1 * 1 卷积核的作用

`1 * 1` 卷积核可以在不改变感受野的情况下，增加模型的非线性（后面的激活函数）。

同时，还可以用它来整合各通道的信息，并输出指定通道数。

# 模型训练与验证

## 模型训练

### 超参数配置

模型训练使用小批量随机梯度下降进行优化，且 `momentum = 0.9`。训练过程中使用 `weight decay` 进行正则化，其中，`L2` 衰减因子设为 $$5e-4$$。在全连接层的前两层，使用了 `dropout`，系数为 `0.5`。

学习速率初始化为 `0.01`，每次且当验证集精度不再改善时，将其减少到 $$1/10$$。在我们的训练中，一共衰减 `3` 次，最后在 `370K` 次迭代（`74 epoch`）时，停止训练。

### 网络初始化问题

网络参数初始化极其重要，因为不好的初始化可能导致模型停滞于不稳定的梯度。所以，我们先用 `A` 模型进行训练，对于 `A` 用随机初始化。然后其后的网络类型（`B-E`）的初始化中，其前四层以及最后的 `3` 层全连接层，用 `A` 的参数进行初始化，其余层进行随机初始化。并且，未减小学习速率。  

对于随机初始化，本文随机采样 `0` 均值，`0.01` 方差的正态分布作为权值，`bias` 则初始化为 `0`。

### 训练图像 rescale

设训练图像(宽长相等)的最小尺寸为 `S`，在图像输入时，还需要进行 `crop` 以及其他预处理（见下面的输入图像处理）。本文是用了两种方式来设置 `S`。  

第一种是，使用固定尺寸的 `S`，这样通过 `crop` 仍能实现 `multi-scale`。本文尝试了 `256` 和 `384` 两种尺寸。首先使用 `256` 的尺寸进行训练。然后直接将其作为 `384` 的初始参数，并将学习速率调低至 `0.001`。

### 输入图像处理

为了获取固定尺寸(`224 * 224`)的输入图像，对 `rescaled` 的训练图像进行随机 `crop`（每次迭代中，每张图只 `crop` 一次）。此外，随后将其进行随机水平翻转，并进行随机 `RGB color shift`。

## 模型验证

### 实现方式

在测试阶段，首先将图像 `rescaled` 到尺寸 `Q`（不一定要等于 `S`）。实验发现，对于每个 `S`，使用多个 `Q` 可以提升性能。  

接着，将全连接层换成卷积层。其中，第一个卷积层换成 `7 * 7` 的卷积层，之后的两个换成 `1 * 1` 的卷积层。然后用这种全卷积网络去推理整个输入图像，得到一个 `class score map`，其通道数正好等于类别数。通过这种方式，就可以实现可变输入尺寸。  

最后，为了获取固定尺寸的图像的分类 `vector`，`class score map` 被求和平均。  

此外，我们还对 `test set` 进行了数据增强：水平翻转，`soft-max` 层计算原始图像和翻转后的图像的得分的平均值，作为最后的结果。

### 具体细节

首先，对于输入为 `224 * 224` 的图像，全连接层的输入为 `7 * 7` 的特征图。通过将全连接层换为 `7 * 7` 卷积层，这就得到了一个 `1 * 1` 的特征图。但是对于输入大于 `224` 的图像，则最后的不为 `1 * 1`，假设最后是 `4 * 4` ，此时，需要对该通道的 `feature map` 进行均值池化，得到 `1 * 1000` 的 `vector`，然后输入到 `softmax` 中，得到最后的概率输出。  

否则，由于全连接层导致输入尺寸固定，可能需要多次 `crop`，虽然准确度稍高，但是运算量更大（多次推理）。转换过程中，直接将全连接层的参数作为卷积层的参数。如下所示：

<div style="text-align:center">
<img src="/images/全连接层参数转换为卷积层.png" width="90%"/>
<p>全连接层替换为卷积层</p>
</div><br>

# classification 实验

## ImageNet 数据集及评估规则

`ILSVRC-2012 dataset` 数据集包含 `1000` 类，分为训练集 (`training`, `1.3M` 张图片)，验证集 ( `validation`, `50k` 张图片)，测试集( `testing`, `10K` 张图片)。

模型评估通过 `top-1` 和 `top-5` 两种方式评估。前者表示推理输出准确率，后者(主要评判规则)表示推理结果中，概率 `top-5` 中，有正确答案的准确率。

## Single Scale evaluation

首先，用单模型结构，单尺度(测试)图像进行评估。对于固定尺寸训练的模型，`Q=S`，对于多尺度训练的模型，$$Q = \frac{1}{2}(S_{min} + S_{max})$$。结果如下图所示：

<div style="text-align:center">
<img src="/images/Single Scale evaluation.png" width="95%"/>
</div><br>

通过上面的实验结果，可以发现如下结论：

- `LRN` 并无作用，所以后续层不再使用（会增加计算量）
- 网络越深，模型准确率越高。相同深度下，`3 * 3` 的卷积核较 `1 * 1` 的更优秀。
- 多尺度训练的模型比单尺度训练的模型效果有显著提升。

## multi-scale evaluation

下面用多尺度测试图像进行验证。注意：训练和测试尺寸的较大差异将会导致模型性能急剧下降。因此，对于固定尺寸 `S` 训练的模型，测试集使用 $${S-32, S, S+32}$$ 三个尺度。对于多尺度 $$[S_{min} , S_{max}]$$ 训练的模型，使用 $$Q={\{S_{min}, 0.5(S_{min} + S_{max}), S_{max}}\}$$ 来推理。  

结果表明，使用多尺度验证，结果会更好。如下所示：

<div style="text-align:center">
<img src="/images/multi-scale evaluation.png" width="95%"/>
</div><br>

## muitl-crop evaluation

下表是 `multi-crop evaluation` 的结果：

<div style="text-align:center">
<img src="/images/muitl-crop evaluation.png" width="95%"/>
</div><br>

## 模型融合

上面都是单模型结果，实际上还可以进行多模型融合。通过将多模型的(`softmax`)输出进行平均，作为最终结果，可以改善表现。实际上，改善的并不多，但是硬件资源开销急剧增加。  

这是因为不同模型之间进行了互补，所以性能得到了改善。

## 与其他模型对比

<div style="text-align:center">
<img src="/images/Multiple ConvNet fusion results.png" width="95%"/>
</div><br>