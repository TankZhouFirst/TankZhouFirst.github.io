---
layout: post
title:  "仿射变换与透视变换"
date:   2020-05-27 23:16:01 +0800
categories: OpenCV
tag: 双目视觉
---

* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**

****

**参考**

- [opencv-张氏标定法(前篇)](https://blog.csdn.net/qq_37059483/article/details/79481014)
- [图像的仿射变换](https://zhuanlan.zhihu.com/p/80852438)
- [图像处理之_仿射变换与透视变换](https://blog.csdn.net/xieyan0811/article/details/71106539)

****

# 仿射变换

## 基本原理

### 定义

仿射变换用于进行平面图像的坐标线性变换，将**二维坐标** $$(x, y)$$ 转换为 $$(u, v)$$ ，其数学表示形式如下：

$$
\left\{\begin{array}{l}
u=a_{1} x+b_{1} y+c_{1} \\
v=a_{2} x+b_{2} y+c_{2}
\end{array}\right.
$$

在图像处理中，可以用仿射变换完成二维图像的**平移、旋转、缩放**等操作。

### 公式推导

用矩阵形式表示上面的变换，其中平移是相加，其他变换为相乘，$$p^{\prime}=m_{1} * p+m_{2}$$，其中，$$p^{\prime}$$ 为变换后的坐标；$$p$$ 变换前的坐标；$$m_1, m_2$$ 分别表示**缩放旋转矩阵**和**平移矩阵**。

$$
\left[\begin{array}{l}
u \\
v
\end{array}\right]=\left[\begin{array}{ll}
a_{1} & b_{1} \\
a_{2} & b_{2}
\end{array}\right]\left[\begin{array}{l}
x \\
y
\end{array}\right]+\left[\begin{array}{l}
c_{1} \\
c_{2}
\end{array}\right]
$$

转换上式为齐次形式，得到 $${D}^{\prime}={M} * {p}$$，即：

$$
\left[\begin{array}{l}
u \\
v \\
1
\end{array}\right]=\left[\begin{array}{lll}
a_{1} & b_{1} & c_{1} \\
a_{2} & b_{2} & c_{2} \\
0 & 0 & 1
\end{array}\right]\left[\begin{array}{l}
x \\
y \\
1
\end{array}\right]
$$

> **新增维度上，转换前后应该值一样。关于齐次的定义和作用，参照另一篇文档《关于齐次坐标的理解》。**

### 变换矩阵

根据上面的定义和公式，求解一个仿射变换矩阵，需要求解 `6` 个未知数，因此需要三组映射点，三点刚好确定一个平面。

### 实例展示

<div style="text-align:center">
<img src="/images/仿射变换图示.png" width="70%">
</div>

<div style="text-align:center">
<img src="/images/平移.jpg" width="30%">
<img src="/images/旋转.jpg" width="30%">
<img src="/images/缩放.jpg" width="30%">
<img src="/images/翻转.jpg" width="30%">
<img src="/images/错切.png" width="30%">
</div>

### 图像变换（插值）

计算得出仿射变换矩阵之后，就能够确定变换前后，每个坐标的对应关系。根据该对应关系，从原始图像中进行采样，就可以得到变换后的图像，称之为 **Image Warping**。由于变换后的像素坐标不一定为整数，因此一般需要进行插值运算。

而坐标关系的运算，又可分为**前向映射**（上图）和**反向映射**（下图）。前向映射一个问题是，输入图像的的两个或多个像素会映射到输出图像的同一个位置，另一种可能是某些输出位置完全没有像素，因此反向映射比前向映射更加有效。

<div style="text-align:center">
<img src="/images/前向映射.png" width="70%">
<img src="/images/反向映射.png" width="70%">
</div>

## 代码实现

### 三特征点计算仿射变换矩阵

**opencv** 提供了进行仿射变换的接口实现：

- **cv2.getAffineTransform(pos1,pos2)** 根据输入的特征点组合（**三个**），计算仿射变换矩阵
- **cv2.warpAffine()** 进行仿射变换

```python
import cv2
import numpy as np

img = cv2.imread('image0.jpg', 1)
height, width = img.shape[:2]  # 405x413

# 在原图像和目标图像上各选择三个点
matSrc = np.float32([[0, 0], [0, height-1], [width-1, 0]])
matDst = np.float32([[0, 0], [30, height-30], [width-30, 30]])

# 得到变换矩阵
matAffine = cv2.getAffineTransform(matSrc, matDst)
# 进行仿射变换
# width,height 为目标尺寸
dst = cv2.warpAffine(img, matAffine, (width, height))
```

### 多特征点计算仿射变换矩阵

但是，如果实际应用中，特征点不是人为标定，而是利用算法识别出来的，则此时可能存在多组对应特征点。此时需要用仿射变换矩阵的公式，进行最小二乘法求解变换矩阵。

根据前面得到的公式 $${D}^{\prime}={M} * {p}$$，假设从变换前后找到对应的 `n` 组特征点，构成齐次项，则变换前后的特征点坐标矩阵尺寸均为 $$3 \times n$$，变换矩阵尺寸为 $$3 \times 3$$，可以求解得到：

$$
M = D^{\prime} \times p^T \times (p \times p^T)^{-1}
$$

然后调用 **warpAffine** 即可进行仿射变换了，详细参数须查阅官方文档。

代码如下所示：

```python
import matplotlib.pyplot as plt
import numpy as np
import cv2


def get_feature_points(img1_color, img2_color, match_thr=0.5):
    '''
    提取两张图像中，匹配的特征点（不通用，根据实际情况调整）

    img1
    img2      : 待匹配的图像
    match_thr : 特征点匹配的阈值，默认为 0.5

    return : src_plist, dist_plist  表示匹配的特征点
    '''
    img1 = img1_color.copy()
    img2 = img2_color.copy()

    # 创建检测器，并搜索特征点，顺序为 x, y
    orb = cv2.ORB_create()
    kp1 = orb.detect(img1, None)
    kp1, des1 = orb.compute(img1, kp1)
    kp2 = orb.detect(img2, None)
    kp2, des2 = orb.compute(img2, kp2)

    # 特征点匹配，保留有效匹配的特征点
    bf = cv2.BFMatcher(cv2.NORM_L2)
    matches = bf.knnMatch(des1, des2, k=2)

    goodMatch = []
    for m, n in matches:
        if m.distance < match_thr * n.distance:
            goodMatch.append(m)

    # 提取有效匹配的特征点
    src_plist = []
    dist_plist = []
    for m, n in matches:
        if m.distance < 0.5 * n.distance:
            src_plist.append(list(kp1[m.queryIdx].pt))
            dist_plist.append(list(kp2[m.trainIdx].pt))

    # 返回特征点列表
    return src_plist, dist_plist


def get_psp_max(img1_color, img2_color, match_thr=0.5):
    '''
    根据输入图像，提取匹配的特征点
    然后根据匹配的特征点列表，利用最小二乘法，获取仿射变换矩阵

    img1
    img2      : 待匹配的图像
    match_thr : 特征点匹配的阈值，默认为 0.5

    return : Mat_x  表示校验得到的仿射矩阵
    '''
    img1 = img1_color.copy()
    img2 = img2_color.copy()

    # 特征点匹配
    img1_plist, img2_plist = get_feature_points(img1, img2, match_thr)

    # 创建矩阵
    # Mat_dst^t = M * Mat_src^t
    Mat_src = np.zeros((len(img1_plist), 3))   # 原始点
    Mat_dst = np.zeros((len(img2_plist), 3))   # 变换后的点

    # 填充矩阵
    for index in range(len(img1_plist)):
        Mat_src[index] = [img1_plist[index][0], img1_plist[index][1], 1]
        Mat_dst[index] = [img2_plist[index][0], img2_plist[index][1], 1]

    # 最小二乘求解
    tmp1 = np.matmul(Mat_dst.transpose((1, 0)), Mat_src)
    tmp2 = np.linalg.inv(np.matmul(Mat_src.transpose((1, 0)), Mat_src))
    Mat_x = np.matmul(tmp1, tmp2)

    # 返回仿射变换矩阵
    return Mat_x


def affine_transfer(img, M, debug_show=False, save_path='out.png'):
    '''
    对输入图像进行仿射变换
    
    img : 输入图像
    M   : 仿射变换矩阵

    debug_show : 是否显示并保存结果，默认不显示
    save_path  : 保存结果的路径，默认为 "out.png"

    return : dist_img 表示仿射变换得到的图像
    '''
    img = img.copy()
    h, w, c = img.shape

    dist_img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))

    if debug_show:
        cv2.imwrite(save_path, dist_img)
        cv2.imshow("result", dist_img)
        cv2.waitKey(0)
        cv2.destroyAllWindows()

    return dist_img
```

# 透视变换

## 基本原理

透视变换用于将 `2D` 矩阵图像变换成 `3D` 的空间显示效果，例如全景拼接等。

透视变换是将图片投影到一个新的视平面，也称作投影映射。它是二维 $$(x, y)$$ 到三维 $$(X, Y, Z)$$，再到另一个二维 $$(x^{\prime}, y^{\prime})$$ 空间的映射。

其基本形式与仿射变换一致，但是第三行用于透视变换。

先通过下式转换到三维空间：

$$
\left[\begin{array}{l}
X \\
Y \\
Z
\end{array}\right]=\left[\begin{array}{lll}
m 11 & m 12 & m 13 \\
m 21 & m 22 & m 23 \\
m 31 & m 32 & m 33
\end{array}\right]\left[\begin{array}{l}
x \\
y \\
1
\end{array}\right]
$$

然后映射到二维空间：

$$
\begin{array}{l}
x^{\prime}=\frac{X}{Z}=\frac{m 11^{*} x+m 12^{*} y+m 13}{m 31^{*} x+m 32+y+m 33} \\
y^{\prime}=\frac{Y}{Z}=\frac{m 21^{*} x+m 22^{*} y+m 23}{m 31^{*} x+m 32^{*} y+m 33}
\end{array}
$$

## 代码实现

### 四特征点实现透视变换

> 参考实例：[图像透视变换](http://www.1zlab.com/wiki/python-opencv-tutorial/opencv-image-prespective-projection/)

```python
import cv2
import matplotlib.pyplot as plt
import numpy as np

img = cv2.imread('sudokusmall.png')
rows,cols,ch = img.shape
# 左图中画面中的点的坐标 四个
pts1 = np.float32([[56,65],[368,52],[28,387],[389,390]])
# 变换到新图片中，四个点对应的新的坐标 一一对应
pts2 = np.float32([[0,0],[300,0],[0,300],[300,300]])

# 生成变换矩阵
M = cv2.getPerspectiveTransform(pts1,pts2)
# 进行透视变换
dst = cv2.warpPerspective(img,M,(300,300))

plt.subplot(121),plt.imshow(img),plt.title('Input')
plt.subplot(122),plt.imshow(dst),plt.title('Output')
plt.show()
```

### 多特征点实现透视变换

参考多特征点实现仿射变换，区别在于将 **warpAffine** 替换成 **warpPerspective**。