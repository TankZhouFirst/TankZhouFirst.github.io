---
layout: post
title:  "RNN 与 LSTM 基本概念"
date:   2019-08-06 21:30:01 +0800
categories: 人工智能
tag: 深度学习基础
---


* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**


****

**参考文献：**  

- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [吴恩达 Coursera 课程](https://www.coursera.org/learn/nlp-sequence-models?ranMID=40328&ranEAID=9IqCvd3EEQc&ranSiteID=9IqCvd3EEQc-EzFTh0zx8Td18rlx4ZYBlA&siteID=9IqCvd3EEQc-EzFTh0zx8Td18rlx4ZYBlA&utm_content=10&utm_medium=partners&utm_source=linkshare&utm_campaign=9IqCvd3EEQc)
- [Pytorch docs](https://pytorch.org/docs/stable/nn.html?highlight=lstm#torch.nn.LSTM)

****

[TOC]

****

# 序列数据处理

## 序列数据简介

序列数据可分为时间序列数据和有序数据结构。例如语音，股票交易价格等为时间序列数据；而文本，基因序列等则属于有序数据结构。

下面以一句话为例：

    某地开设了大量工厂，空气污染十分严重……这里的天空都是???色的

要预测上面天空颜色，需要结合上文，这里应该填灰色。  

## CNN 处理序列数据

`CNN` 处理序列数据，是通过滑窗的方式进行的，从而利用前后发生的事情预测当前所发生的情况，如下所示：

<div style="text-align:center">
<img src="\images/CNN 处理序列数据.gif" width="60%">
</div><br>

但其所能考虑到的前后依赖受限于将多少个向量`（window size）`拼接在一起。所能考虑的依赖始终是固定长度的。可以通过扩大并接向量的数量来拓展前后依赖关系，但这样会导致权值参数的数目急剧增加，其中很多权重都是冗余的。

但是，问题更关键的点在于，`CNN` 训练所需要的数据量很大。

<div style="text-align:center">
<img src="\images/CNN 处理序列数据 2.gif" width="90%">
</div><br>

左侧是时间维度展开前，右侧是展开后：单位时刻实际工作的只有灰色部分。`CNN` 的特点使不同时刻的预测完全是独立的。我们只能通过窗处理的方式让其照顾到前后相关性。

## 循环神经网络处理序列数据

如下图所示，为循环神经网络的原理。左侧是时间维度展开前，回路方式的表达方式，其中黑方框表示时间延迟。右侧展开后，可以看到当前时刻的输出 $$h_t$$ 并不仅仅取决于当前时刻的输入 $$x_t$$ ，同时与上一时刻的输出 $$h_{t-1}$$ 也相关。：

<div style="text-align:center">
<img src="\images/RNN 处理序列数据.gif" width="90%">
</div><br>

**所有时刻的权重矩阵都是共享的。这是递归网络相对于 `CNN` 而言最为突出的优势。时间结构共享是循环神经网络的核心中的核心。**

# 时序网络的通用框架

## 网络整体结构

网络需要支持信息持久化，可以被看做是同一神经网络的多次复制，每个神经网络模块会把消息传递给下一个。其结构如下所示：

<div style="text-align:center">
<img src="\images/循环神经网络基本结构.jpeg" width="90%">
</div><br>

如上图所示，为序列数据处理网络的通用架构。左边是其实际的结构；右边是按时序展开后得到结构。因此，其能处理任意长度的序列数据。

> **要注意的是，右边部分并非实际的结构，左边才是。** 

## 前向传播过程

每个时刻 `t`，将当前时刻的输入 $$x_t$$，以及上一时刻的输出 $$h_{t-1}$$（0 时刻对应的 h 可初始化为 0）进行拼接，作为 `t` 时刻的输入，进行相关运算后，得到当前时刻的输出 $$h_t$$。逐时刻进行，如此往复，直到序列处理完毕。  

> 正是由于这种结构设计，所以 **RNN 等网络的参数在不同时刻是共享的**。

为了将当前时刻的状态转换为最终的输出，循环神经网络还需要另一个网络来完成这一过程。且不同时刻用于输出的网络的参数也一样。

如下所示，是前向传播的直观计算过程，所有时刻参数共享(数据循环经过一个网络，所以称之为循环神经网络)：

<div style="text-align:center">
<img src="\images/RNN 内部结构.jpg" width="95%">
</div><br>

$$
\begin{aligned}
h_t &= tanh(w_t \times cat(h_{t-1}, x_t) + b_t) \\

y_t &= w^`_t \times h_t + b^`_t
\end{aligned}
$$

## 模型的特点

- **时序长短可变**：

    只要知道上一时刻的隐藏状态 $$h_{t-1}$$  与当前时刻的输入 $$x_t$$，就可以计算当前时刻的隐藏状态 $$h_{t}$$。并且由于计算所用到的 $$W_{xh}$$ 与 $$W_{hh}$$  在任意时刻都是共享的。递归网络可以处理任意长度的时间序列。

    实际代码实现中表现为，训练过程和推理过程的时间步长可以不相等。

- **过去时间依赖**：

    若当前时刻是第 5 帧的时序信号，那计算当前的隐藏状态 $$h_{5}$$ 就需要当前的输入 $$x_{5}$$ 和第 4 帧的隐藏状态 $$h_{4}$$，而计算 $$h_{4}$$ 又需要 $$h_{3}$$，这样不断逆推到初始时刻为止。意味着常规递归网络对过去所有状态都存在着依赖关系。

## 时序网络的应用类别

在实际应用中，并不是每一时刻都有对应的输出，据此可分为如下几种网络：

### one-to-one

<div style="text-align:center">
<img src="\images/one-to-one.png" width="30%">
</div>

### one-to-many

这种结构常用于是个或者曲目创作，或者根据图像生成文字描述等问题。此时输入一个初始控制值，系统自动的根据上一时刻的输入生成当前时刻的输出。

<div style="text-align:center">
<img src="\images/one-to-many.png" width="60%">
</div>

### many-to-one

这种情况常用于情感分析系统之类的，或者视频，文本分类等等。比如说需要根据文本评定表达的情感或者评分。此时输出只有一个。

<div style="text-align:center">
<img src="\images/many-to-one.png" width="60%">
</div>

### many-to-many

前面讲到的模型就是多对多的模型，用于检测自然语言中各个词汇的属性，此时为多对多，且输入输出长度一样。这种广泛的用于序列标注。

<div style="text-align:center">
<img src="\images/many-to-many.png" width="60%">
</div>

### many-to-many

这种情况常用于机器翻译领域。因为不同的语种其表达相同意思的自然语言序列可能不同。

<div style="text-align:center">
<img src="\images/many-to-many2.png" width="70%">
</div>

# 循环神经网络（RNN, Recurrent Neural Network）

## 网络核心结构

`RNN` 的核心部分如下所示。其前后信息只通过 `tanh` 函数进行连接。

<div style="text-align:center">
<img src="\images/RNN 结构.jpeg" width="90%">
</div>

## 缺陷

`RNN` 能够将之前的信息联系到当前的时刻中。但是当上下文较长时，网络需要记住之前较长时刻的信息。而简单的 `RNN` 很容易发生 **梯度消失**，**梯度爆炸** 等问题。

主要是在 `RNN` 中，前后信息的交接，是通过 `tanh` 激活函数实现的（输出在 `0~1` 之间）。所以在反向传播阶段，由于链式求导法则，对时间上的追溯，很容易发生系数矩阵的累乘，导致梯度消失。（`RNN` 的反向传播参考另一篇笔记《深度学习中的反向传播算法》）  

即使未出现梯度消失或梯度爆炸，也可能会出现梯度下降问题，即：越前面的数据进入序列的时间越早，所以对后面的数据的影响也就越弱，简而言之就是一个数据会更大程度受到其临近数据的影响。

但是我们很有可能需要更长时间之前的信息，而这个能力传统的 `RNN` 特别弱，于是有了 `LSTM` 这个变体。

# 长短期记忆网络（LSTM, Long Short-Term Memory）

## 简介

`LSTM` 适合于处理和预测时间序列中间隔和延迟相对较长的重要事件。

`LSTM` 已经在科技领域有了多种应用。基于 `LSTM` 的系统可以学习翻译语言、控制机器人、图像分析、文档摘要、语音识别图像识别、手写识别、控制聊天机器人、预测疾病、点击率和股票、合成音乐等等任务。 

## 网络核心结构

<div style="text-align:center">
<img src="\images/LSTM.jpeg" width="95%">
</div><br>

如上图所示，`LSTM` 通过门的控制，可以有效的防止梯度消失（但仍可能发生，详见《`RNN` 中的梯度消失和梯度爆炸》）。其中符号定义如下所示：

<div style="text-align:center">
<img src="\images/LSTM 符号标志.png" width="90%">
</div>

## LSTM 核心思想

`LSTM` 的关键在与细胞状态，如下图所示，细胞状态沿最上面的水平线传递。`cell` 状态类似于输送带。它直接在整个链上运行，只有一些少量的线性相互作用。信息在上面流传保持不变会很容易。

`LSTM` 的精髓就在于 `3` 个门，`forget`，`input` 和 `output`，围绕这 3 个门的公式也是基本相似，所以记忆 `LSTM` 的公式其实相当简单。

<div style="text-align:center">
<img src="\images/LSTM 核心思想.png" width="70%">
</div>

## 整体流程

`LSTM` 的整体结构如下所示，其中，`f, i, o` 分别表示遗忘门，输入门，以及输出门。

<div style="text-align:center">
<img src="\images/LSTM 整体计算.jpg" width="95%">
</div>

### 遗忘门（舍弃部分细胞状态）

通过遗忘门，控制舍弃细胞状态中哪些信息。此步骤根据当前时刻的信息，控制删除历史状态中的部分信息。如下图所示：

<div style="text-align:center">
<img src="\images/forget.jpg" width="95%">
</div><br>

首先将上一时刻的输出 $$h_{t-1}$$ 和当前时刻的输入 $$x_t$$ 进行拼接，然后通过神经网络进行转换，最后通过 `sigmoid` 激活函数，得到 0~1 之间的数值 $$f_t$$。然后 $$f_t$$ 与 $$C_{t-1}$$ 之间对应元素相乘，从而控制细胞状态对应值的取舍。1 表示“完全保留”，0 表示“完全舍弃”。

### 输入门（存储当前时刻的信息到细胞状态中）

下一步是决定向细胞状态中加入什么新的信息。此步骤根据当前时刻信息，决定添加什么信息到细胞状态中。这里包含两个部分。第一，`tanh` 层创建一个新的候选值向量 $$\tilde{C}_t$$。然后，`sigmoid` 层称 “输入门层”，决定什么值将被添加到细胞状态中。

<div style="text-align:center">
<img src="\images/input.jpg" width="95%">
</div>

### 更新细胞状态  

此步骤更新细胞状态，得到更新的细胞状态，包含历史和当前时刻信息。

<div style="text-align:center">
<img src="\images/update.jpg" width="95%">
</div>

### 输出门（输出隐藏状态）

最终，我们需要确定输出什么值。这个输出将会基于我们的细胞状态，但是也是一个过滤后的版本。首先，我们运行一个 `sigmoid` 层来确定细胞状态的哪个部分将作为输出。接着，我们把细胞状态通过 `tanh` 进行处理（得到一个在 `0~1` 之间的值）并将它和 `sigmoid` 门的输出相乘，最终我们仅仅会输出我们确定输出的那部分。

输出会作为下一时刻的输入，同时可经过其他网络，作为当前时刻的输出。

<div style="text-align:center">
<img src="\images/output.jpg" width="95%">
</div>

## LSTM 变体 GRU

门控循环单元（`Gated Recurrent Unit，GRU`）只有 2 个门，即：“更新门”和“重置门”。

`GRU` 的两个门：一个是“更新门”（`update gate`），它将 `LSTM` 的“遗忘门”和“输入门”融合成了一个“门”结构；另一个是“重置门”（`reset gate`）。“从直观上来说，‘重置门’决定了如何将新的输入信息与前面的记忆相结合，‘更新门’定义了前面记忆保存到当前时刻的量。” “那些学习捕捉短期依赖关系的单元将趋向于激活‘重置门’，而那些捕获长期依赖关系的单元将常常激活‘更新门’。”

其结构如下所示：

<div style="text-align:center">
<img src="\images/GRU.png" width="90%">
</div>

# 模型增强

## 双向 RNN（bidirectional RNN）

在有些问题中，当前时刻的输出不仅与之前的状态有关，还与之后的状态有关。此时需要使用双向循环神经网络来解决。双向神经网络是由两个循环神经网络叠加在一起实现的，输出由这两个循环神经网络的状态共同决定。

如下图所示，双向循环神经网络的主体结构就是两个单向循环神经网络的结合。在每一个时刻 `t`，输入会同时提供给这两个方向相反的循环神经网络，而输出则是由这两个单向的循环神经网络共同决定。双向循环神经网络的前向传播过程和单向的循环神经网络十分类似。

<div style="text-align:center">
<img src="\images/双向 RNN.png" width="85%">
</div><br>

双向 `RNN` 可以在同一时刻获取序列中前部分和后部分的信息。

```python
He said, "Teddy bears are on sale!"
He said, "Teddy Roosevelt was a great President!"
```

如上面的语句所示，当检测到 `Teddy` 时，并不知道其是否为人名的一部分，仅仅考虑前半部分是不够的。

## 深度 RNN

深层循环神经网络是循环神经网络的另一种变种。为了增强模型的表达能力，可以将每一时刻上的循环重复多次。和卷积神经网络一样，每一层上，循环体的参数共享，而不同层的参数不同。

<div style="text-align:center">
<img src="\images/深度 RNN.jpg" width="80%">
</div><br>

一般来说，单层多时刻的网络已经相当规模了。所以深度 `RNN` 一般为 三层，每一层共用一组参数。也有更深的结构，但是仅限于单一时刻，各时刻之间没有水平连接。

## 循环神经网络的 dropout

类似于卷积神经网络，在最后的全连接层使用 `dropout`，循环神经网络一般只在不同的层循环体结构之间使用 `dropout`，而不在同一层的循环体之间使用。

# LSTM Pytorch 接口

## LSTM 层定义

### 原型

```python
class torch.nn.LSTM(*args, **kwargs)
```

### 参数

**input_size**  

表示每一个时刻，网络的输入尺寸（单样本）

**hidden_size**

表示隐藏层的尺寸。隐藏层即 LSTM 的输出（非整个网络的）尺寸。参照上面图中的 $$h_t$$ 的长度，只有再经过一个网络，才能得到最终的输出 $$y_t$$。

**num_layers**

表示堆叠几层的 `LSTM`，默认是 1。可以参照 *深度 RNN* 部分，即竖向的堆叠层数。

**bias**

True 或者 False，决定是否使用 bias。默认为 True。

**batch_first**

输入输出的第一维是否为 `batch_size`，默认值 False，即：`[time_step, batch_size, input_size]`

**dropout**

默认值 0。是否在除最后一个 `RNN` 层外的其他 `RNN` 层后面加 `dropout` 层。输入值是 `0-1` 之间的小数，表示概率。0 表示 0 概率 `dropout`，即不使用 `dropout`

**bidirectional**

是否是双向 RNN，默认为：False。

### **实例**

比如说有 5 句话，每句话由 10 个单词组成，所有单词中最长的尺寸为（字符数）为 12，则可以如下定义：

```python
lstm = nn.LSTM(
        input_size  = 12,
        hidden_size = 128, # 这个随便定义
        batch_first = True)
```

## LSTM 使用

### 输入格式

LSTM 的输入为：

```python
 input, (h_0, c_0)
```

**input**  

尺寸为 `(seq_len, batch_size, input_size)`，维度顺序需要根据前面 LSTM 的定义来。如果 `batch_first=True`，则为：`(batch_size, seq_len, input_size)`

其中，`seq_len` 表示时间步长度，`input_size` 表示单时间步输入尺寸。

**h0**  

可选，即 LSTM 中，来自于上一时刻输出的初始值。尺寸为：`(num_layers * num_directions, batch, hidden_size)`。

如果为单向 RNN，则 `num_directions=1`，如果为双向 RNN，则 `num_directions=2`。

**c0**  

可选，即 LSTM 中，初始细胞状态。尺寸为：`(num_layers * num_directions, batch, hidden_size)`。

如果为单向 RNN，则 `num_directions=1`，如果为双向 RNN，则 `num_directions=2`。

### 输出格式

LSTM 的输出为：

```python
output, (hn,cn)
```

**output**  

`out` 是每一个时间步的最后一个隐藏层 `h` 的输出，假如有 `5` 个时间步（即 `seq_len=5` ），则有 5 个对应的输出，`out` 的维度是：(`seq_len, batch_size, hidden_size`)，如果 `batch_first=True`，则为：(`batch_size,  seq_len, hidden_size`)


**也就是说，有多少输入，就有多少输出，即：每个时间步，都有一个输出。**

**hn**  

尺寸为：`(num_layers * num_directions, batch_size, hidden_size)`

**cn**  

尺寸为：`(num_layers * num_directions, batch_size, hidden_size)`

### 参数初始化

所有的参数和偏置默认初始化为 $$u(-\sqrt{k}, \sqrt{k})$$ 之间的值，其中，$$k = \frac{1}{hidden_{size}}$$。

### 说明

`LSTM` 定义时，只是定义了一个网络。在训练阶段，可以根据输入来假想展开成多少个时间步。比如，将一本小说，切分成 25 个字为一个样本，预测下一个字，其中，共有 3000 个不同的字，则应该如下定义：

1. 定义 LSTM 网络时，LSTM 输入尺寸为 3000，输出尺寸也为 3000
2. 使用 LSTM 网络时，展开的时间步为 25，每 25 个时间步，获取一个输出。

# 实例代码

## MNIST 手写体识别

```python
## 依赖包导入

​```python
import os
import torch
import torch.nn as nn
import torch.utils.data as Data
import torchvision
​```

## 参数设置

​```python
# Hyper Parameters
# train the training data n times, to save time, we just train 1 epoch
EPOCH = 1
BATCH_SIZE = 50
LR = 0.001          # learning rate
DOWNLOAD_MNIST = False
​```

## 数据集准备

​```python
# Mnist digits dataset
if not (os.path.exists('./mnist/')) or not os.listdir('./mnist/'):
    # not mnist dir or mnist is empyt dir
    DOWNLOAD_MNIST = True

train_data = torchvision.datasets.MNIST(
    root='./mnist/',
    train=True,  # this is training data
    transform=torchvision.transforms.ToTensor(),  # Converts a PIL.Image or numpy.ndarray to
    # torch.FloatTensor of shape (C x H x W) and normalize in the range [0.0, 1.0]
    download=DOWNLOAD_MNIST,
)

# Data Loader for easy mini-batch return in training, the image batch shape will be (50, 1, 28, 28)
train_loader = Data.DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)

# pick 2000 samples to speed up testing
test_data = torchvision.datasets.MNIST(root='./mnist/', train=False)
test_x = torch.unsqueeze(test_data.test_data, dim=1).type(torch.FloatTensor)[
         :2000] / 255.  # shape from (2000, 28, 28) to (2000, 1, 28, 28), value in range(0,1)
test_y = test_data.test_labels[:2000]
​```

## 模型创建

# 下面创建一个 `LSTM` 模型，其中，输入向量长度为 `28`， 隐藏层尺寸为 `64`， 每个时刻对应的网络只有一层级联，输出尺寸为 `10`。

​```python
class RNN(nn.Module):
    def __init__(self):
        super(RNN, self).__init__()
        self.rnn = nn.LSTM(
          # 每个时间步输入尺寸为 28，那么需要 28 个时间步为一张图片
            input_size=28,
            hidden_size=64,
            num_layers=1,    # 竖直方向上只有一个 LSTM
            batch_first=True
        )
        self.out = nn.Linear(64, 10)  # fully connected layer, output 10 classes

    def forward(self, x):
        r_out, (h_n, h_c) = self.rnn(x, None)  # None 表示 hidden state 会用全 0 的 state
        # r_out = [BATCH_SIZE, input_size, hidden_size]
        # r_out[:, -1, :] = [BATCH_SIZE, hidden_size]  '-1'，表示选取最后一个时间步的 r_out 作为输出
        # 因为每个时间步都有输出，而这里识别只需要最后一个时间步即可
        out = self.out(r_out[:, -1, :])
        # out = [BATCH_SIZE, 10]
        return out

rnn = RNN()
​```

## 选择损失函数和优化器

​```python
optimizer = torch.optim.Adam(rnn.parameters(), lr=LR)  # optimize all cnn parameters
loss_func = nn.CrossEntropyLoss()  # the target label is not one-hotted
​```

## 开始训练

​```python
for epoch in range(EPOCH):
    for step, (x, b_y) in enumerate(train_loader):  # gives batch data
        b_x = x.view(-1, 28, 28)  # reshape x to (batch, time_step, input_size)
        output = rnn(b_x)  # rnn output
        loss = loss_func(output, b_y)  # cross entropy loss
        optimizer.zero_grad()  # clear gradients for this training step
        loss.backward()  # backpropagation, compute gradients
        optimizer.step()
​```

## 模型测试

​```python
test_output = rnn(test_x[:10].view(-1, 28, 28))
pred_y = torch.max(test_output, 1)[1].data.numpy().squeeze()

print(pred_y, 'prediction number')
print(test_y[:10], 'real number')
​```
```

## LSTM 股票预测

代码详见 [Github](https://github.com/TankZhouFirst/Pytorch-LSTM-Stock-Price-Predict)

