---
layout: post
title:  "DenseNet"
date:   2020-05-29 08:07:01 +0800
categories: 人工智能
tag: 图像分类
---

* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**

****

**参考**

-   [Densely Connected Convolutional Networks](https://arxiv.org/pdf/1608.06993.pdf)

****

# 引入

## 要解决的问题

本文主要动机在于强化 **shortcut** 这一思路。或者说解决如下问题：随着信息或梯度的逐层传递，可能会逐渐消失。

个人觉得，这不是根本动机，根本目的可能只是想尝试一下全部短接的效果而已，意外的发现是有用的。

## 主要思路

主要思路就是，每一层的输出，均作为后续所有层的输入。可以将之当成全部变量，作用域始于其生成之时。

而每一层的输入为之前所有层的输出的组合（**concatenate**），即：$$\mathbf{x}_{\ell}=H_{\ell}\left(\left[\mathbf{x}_{0}, \mathbf{x}_{1}, \dots, \mathbf{x}_{\ell-1}\right]\right)$$，其中，$$H_l$$ 构成为 **BN + ReLU + Conv**。



<div style="text-align:center">
<img src="/images/dense block.png" width="80%"/>
<p>图 1：dense block</p>
</div><br>

## 主要成就

该设计主要有如下**优势**：

1.  模型结构更简单，参数更少，更易优化，收敛更快，精度更高
2.  完美实现**特征复用**，每一层只需要关注新特征的生成即可，而不用重复生成之前层的特征。因此，网络可以做的很窄！

# 详解

<div style="text-align:center">
<img src="/images/DenseNet.PNG" width="96%"/>
<p>图 2：DenseNet</p>
</div><br>

如上图所示，为一个包含 `3` 个**dense block** 的 **denseNet**。不同 **blocks** 之间的层称之为 **transition layers**，进行**卷积和池化**，构成为：**BN + $$1 \times 1$$ 卷积 + $$2 \times 2$$ 池化**。

此外，`DenseNet` 的每一层的通道数一样，通过超参数 **k** 设定。由于特征复用，**DenseNet** 的网络可以做的很窄。

尽管如此，随着层数的增加，后续层的输入特征数也是极高的，因此可以使用 $$1 \times 1$$ 卷积层来减少输入特征数，即 **bottleneck**，提升运算效率。将其记为 **DenseNet-B**。

为了进一步提升运算效率，可以在 **transition layers** 中减少特征图数目，系数设定为 $$\theta$$。我们设定 $$\theta=0.5$$，得到 **DenseNet-C**。

同时结合 **bottleneck** 和 **$$\theta$$**，可以得到 **DenseNet-BC**。

<div style="text-align:center">
<img src="/images/DenseNet 网络结构.png" width="96%"/>
<p>表 1：DenseNet 网络结构</p>
</div><br>

其中，$$k=32$$，**conv** 表示 **BN-ReLU-Conv**。

# 试验和结果

>   详细实验细节，参考原论文。

<div style="text-align:center">
<img src="/images/DenseNet 性能表现.png" width="96%"/>
<p>表 2：DenseNet 性能表现</p>
</div><br>

<div style="text-align:center">
<img src="/images/DenseNet 在 ImageNet 上的表现.png" width="45%"/>
<p>表 3：DenseNet 在 ImageNet 上的表现</p>
</div><br>

<div style="text-align:center">
<img src="/images/DenseNet VS ResNet.PNG" width="95%"/>
<p>图 3：DenseNet VS ResNet</p>
</div><br>