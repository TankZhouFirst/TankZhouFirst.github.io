---
layout: post
title:  "Pytorch 自动求导"
date:   2019-08-20 13:39:01 +0800
categories: 人工智能
tag: Pytorch
---

* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**

****

**参考**

- [Autograd: Automatic Differentiation](https://pytorch.org/tutorials/beginner/blitz/autograd_tutorial.html#sphx-glr-beginner-blitz-autograd-tutorial-py)

****

`autograd` 包提为所有的 `Tensor` 操作供自动求导功能，且它是运行时的框架，这意味着，反向传播顺序与代码运行顺序一致。

## Tensor

`torch.Tensor` 是该包的核心功能。如果将其 `.requires_grad` 属性设置为 `True`（默认为 `False`），则将开始追踪发生于它上面的所有操作。在计算结束之后，可以调用 `.backward()` 函数，它将自动计算所有的梯度。该 `tensor` 的梯度将会**累积**到 `.grad` 属性。

要停止追踪一个 `tensor`，可以调用 `.detach()` 函数，来将其剥离计算历史，并防止未来的计算中对其进行追踪。

此外，可以通过使用 `with torch.no_grad():` 上下文环境，来避免追踪计算历史。在进行模型评估时，该技术极其有用。因为此时模型不需要计算梯度。

此外，还有一个对于自动求导的实现而言，很重要的类，即：`Function`。

`Tensor` 和 `Function` 相互关联，并构建一个无环图，该无环图即为运算的编码。每一个具有 `.grad_fn` 属性的 `Tensor`，都将调用一个 `Functiuon` 对象来创建 `Tensor`，除了哪些用户手动创建的 `Tensor`（对应的 `.grad_fn` 属性为 `None`）。这句话的意思是，所有运算的中间 `Tensor`，都是通过 `.grad_fn` 自动创建的。

如果想要计算微分，可以对 `tensor` 调用 `.backward()` 函数。如果该 `Tensor` 为标量，则无需为 `.backward()` 指定参数；若为 `Tensor` 不为标量，则需要为 `.backward()` 指定参数 `gradient`，它为一个 `tensor`，尺寸与 `tensor` 匹配。

```python
a = torch.randn(2, 2)
a = ((a * 3) / (a - 1))

print(a.requires_grad)  # False

a.requires_grad_(True)
print(a.requires_grad)  # True

b = (a * a).sum()
print(b.grad_fn)        # <SumBackward0 object at 0x12665ad68>
```

## 梯度

如果向量 $\vec{x}$ 对应的输出为 $\vec{y}$，则 `y` 对 `x` 的导数为：
$$
J=\left(\begin{array}{ccc}{\frac{\partial y_{1}}{\partial x_{1}}} & {\cdots} & {\frac{\partial y_{1}}{\partial x_{n}}} \\ {\vdots} & {\ddots} & {\vdots} \\ {\frac{\partial y_{m}}{\partial x_{1}}} & {\cdots} & {\frac{\partial y_{m}}{\partial x_{n}}}\end{array}\right)
$$
一般说来，torch.autograd 将会计算雅克比矩阵（vector-Jacobian）乘积。也就是说，对于任意给定的向量 $v=\left(\begin{array}{llll}{v_{1}} & {v_{2}} & {\cdots} & {v_{m}}\end{array}\right)^{T}$，计算 $v^{T} \cdot J$。

## 自定义求导

```python
import torch


class MyReLU(torch.autograd.Function):
    """
    We can implement our own custom autograd Functions by subclassing
    torch.autograd.Function and implementing the forward and backward passes
    which operate on Tensors.
    """

    @staticmethod
    def forward(ctx, input):
        """
        In the forward pass we receive a Tensor containing the input and return
        a Tensor containing the output. ctx is a context object that can be used
        to stash information for backward computation. You can cache arbitrary
        objects for use in the backward pass using the ctx.save_for_backward method.
        """
        ctx.save_for_backward(input)
        return input.clamp(min=0)

    @staticmethod
    def backward(ctx, grad_output):
        """
        In the backward pass we receive a Tensor containing the gradient of the loss
        with respect to the output, and we need to compute the gradient of the loss
        with respect to the input.
        """
        input, = ctx.saved_tensors
        grad_input = grad_output.clone()
        grad_input[input < 0] = 0
        return grad_input


dtype = torch.float
device = torch.device("cpu")
# device = torch.device("cuda:0") # Uncomment this to run on GPU

# N is batch size; D_in is input dimension;
# H is hidden dimension; D_out is output dimension.
N, D_in, H, D_out = 64, 1000, 100, 10

# Create random Tensors to hold input and outputs.
x = torch.randn(N, D_in, device=device, dtype=dtype)
y = torch.randn(N, D_out, device=device, dtype=dtype)

# Create random Tensors for weights.
w1 = torch.randn(D_in, H, device=device, dtype=dtype, requires_grad=True)
w2 = torch.randn(H, D_out, device=device, dtype=dtype, requires_grad=True)

learning_rate = 1e-6
for t in range(500):
    # To apply our Function, we use Function.apply method. We alias this as 'relu'.
    relu = MyReLU.apply

    # Forward pass: compute predicted y using operations; we compute
    # ReLU using our custom autograd operation.
    y_pred = relu(x.mm(w1)).mm(w2)

    # Compute and print loss
    loss = (y_pred - y).pow(2).sum()
    print(t, loss.item())

    # Use autograd to compute the backward pass.
    loss.backward()

    # Update weights using gradient descent
    with torch.no_grad():
        w1 -= learning_rate * w1.grad
        w2 -= learning_rate * w2.grad

        # Manually zero the gradients after updating weights
        w1.grad.zero_()
        w2.grad.zero_()
```





























































































































































