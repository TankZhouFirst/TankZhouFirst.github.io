---
layout: post
title:  "GANs tutorial"
date:   2019-08-14 06:09:01 +0800
categories: 人工智能
tag: GANs
---

* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**

****

**参考**

- [NIPS 2016 Tutorial: Generative Adversarial Networks](https://arxiv.org/abs/1701.00160)

****

# 主要内容

本文主要内容

本文主要介绍如下内容：

1. 为何生成模型是一个值得研究的课题？
2. 生成模型如何工作？`GANs` 与其他生成模型对比如何？
3. `GANs`  的原理细节？
4. `GANs` 的前沿研究？
5. 当下结合 `GANs` 和其他方法的图像处理模型

# 为何研究生成模型

生成模型只能用于生成数据，而不能用于评估概率密度函数，那么我们研究它有何意义呢？有以下几点：

- 训练生成模型，并从生成数据中采样，是一种表征我们能够表示和操控高维度概率分布的优秀的测试方式。而高维度概率分布是许多应用数学和工程领域的重要目标

- **生成模型可以以多种方式，与强化学习进行结合**。强化学习策略可以分为两类：基于模型的（`model-based`）和不依赖与模型的（`model-free`）。其中，基于模型的算法需要包含一个生成模型。而时序生成模型的数据可用于模拟可能的未来，其对于强化学习而言，非常有用。另一种结合方式是，生成模型可以使能模型在虚拟环境中进行学习。

- **生成模型，尤其是 `GANs` 能够很好的使用半监督学习来取得不错的效果**。生成模型可以使用缺失数据进行训练，且能够对缺失数据的输入进行推理。一个典型的例子就是，半监督学习（`semi-supervised learning`），其中存在大量的 `label` 甚至训练数据缺失。而当代大多数的模型需要极其丰富的带标签的数据来取得良好的泛化性能。

- **生成模型，尤其是 `GANs`，使得机器学习能够使用多模态输出（`multi-modal outputs`）**。对于许多任务，一个输入可能对应多个正确的输出。而许多传统的机器学习方法中，使用的是均方差误差，因此其结果更倾向于对数据进行折中，导致结果并不理想，如下所示：

    <div style="text-align:center">
    <img src="/images/GANs 示例视频帧.png" width="80%"/>
    <p>GANs 示例视频帧</p>
    </div><br>

除了上面的需求外，许多任务还需要优质样本的生成，例如：

- **单图超像素生成**（`Single image super-resolution`）。在这类任务中，目标是以低分辨率图像为输入，综合出高分辨率图像。其需要生成模型，因为这类任务需要模型引入更多的信息（生成）到原图中。

    <div style="text-align:center">
    <img src="/images/超像素生成.png" width="95%"/>
    <p>超像素生成</p>
    </div><br>

- **艺术创作任务**。可以用生成模型，尤其是 `GANs` ，创建交互式程序，来辅助用户创建真实图像。

    <div style="text-align:center">
    <img src="/images/艺术创作任务.png" width="60%"/>
    <p>艺术创作任务</p>
    </div><br>

- **图像转换任务**。例如卫星图和地图的相互转换，风格迁移等。

# 生成模型如何工作

## 极大似然估计

为了简化论证，我们这里只考虑使用最大似然估计原则的生成模型。并非所有的模型均使用最大似然估计，尽管如此，我们仍能够将其转换成使用最大似然估计的方式，例如 `GANs`。

最大似然估计的基本思想是，定义一个模型，其对概率密度进行评估，参数为 $$\theta$$。接着，我们定义似然（`likehood`）为模型在训练数据上的概率：$$\prod_{i=1}^{m} p_{\text { model }}\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right)$$，其中，$$x^{(i)}$$ 表示第 `i` 个样本。换言之，其为模型作用与所有样本所得的概率之积。

极大似然估计的核心点在于，选择合适的参数 $$\theta$$，使得上面的似然积最大。而乘积形式不好求解，因此可以使用对数似然转换为求和形式。

$$
\begin{aligned} \boldsymbol{\theta}^{*} &=\underset{\boldsymbol{\theta}}{\arg \max } \prod_{i=1}^{m} p_{\text { model }}\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right) \quad\quad\quad(1)\\
&=\underset{\boldsymbol{\theta}}{\arg \max } \log \prod_{i=1}^{m} p_{\text { model }}\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right) \quad\quad\quad(2)\\ 
&=\underset{\boldsymbol{\theta}}{\arg \max } \sum_{i=1}^{m} \log p_{\text { model }}\left(\boldsymbol{x}^{(i)} ; \boldsymbol{\theta}\right) \quad\quad\quad(3)
\end{aligned}
$$

此外，根据下面推导，我们可以将极大似然转换为 `KL` 散度，其中，$$p_G$$ 即 $$p_{model}$$（**下面证明感觉有问题，第二行到第三行怎么来的，求教**）：

$$
\boldsymbol{\theta}^{*}=\underset{\boldsymbol{\theta}}{\arg \min } D_{\mathrm{KL}}\left(p_{\mathrm{data}}(\boldsymbol{x}) \| p_{\text { model }}(\boldsymbol{x} ; \boldsymbol{\theta})\right)  \quad\quad\quad(4)
$$

证明：

$$
\begin{aligned}
\theta^* &= arg\max_{\theta}\sum_{i=1}^mlog(P_G(x_i;\theta)) \approx arg\max_{\theta}E_{x \sim p_{data}}log(P_G(x;\theta)) \\
&= arg\max_{\theta} \int {P_{data}(x)log(P_G(x;\theta))} \,{\rm d}x \\ 
&= arg\max_{\theta} \int {P_{data}(x)log \frac{P_G(x;\theta)}{P_{data}(x)}} {\rm d}x \\ 
&= arg\min_{\theta} \int {P_{data}(x)log \frac{P_{data}(x)}{P_G(x;\theta)}} {\rm d}x \\ 
&= arg\min_{\theta} KL(P_{data}(x) || P_G(x;\theta))
\end{aligned}
$$

上式说明，`MLE` 等价于最小化 `KL` 散度，这种散度衡量了两个分布之间的差异。实际上，我们并无整个原始数据分布 $$p_{data}$$，只有从中采样的 `m` 个样本，我们将之定义为 $$\hat{p}_{data}$$。

## 深度生成模型的分类

如下图所示，为生成模型的分类树。

<div style="text-align:center">
<img src="/images/生成模型分类树.png" width="80%"/>
<p>生成模型分类树</p>
</div><br>

如上图所示，每个叶子节点所对应的模型，均存在或多或少的不足。`GANs` 解决了这些不足，但同时，其引入了新的不足。

### 显式密度模型

显式密度模型（`explicit density function`）又分为 `tractable explicit models` 和 `approximate explicit model` 。其中，前者通常可以直接通过数学方法来建模求解；后者通常无法直接对数据分布进行建模，需要利用数学里的一些近似方法来做数据建模。

显式密度模型的难点在于，如何设计一个模型，能够捕获将被生成的数据的所有的复杂度的同时，保持计算的简易性。

面对这一挑战，存在两种不同的策略（详解建参考[论文](https://arxiv.org/abs/1701.00160)）：

1. 精巧的结构设计，来保证其计算可行性
2. 使用似然和梯度的近似计算

### 隐式密度模型

这类模型无需显式的定义密度函数，其提供一种方式来训练模型，同时仅与 $$p_{model}$$ 进行非直接交互，通常做法是对其进行采样。

部分这类模型从 $$p_{model}$$ 进行采样，其定义一个马尔科夫链，需要执行多次来从模型获取一个样本。代表模型为生成随机网络（`generative stochastic network, GSN`）。但是，马尔科夫链不能拓展至高维空间，且计算量较大。

对于以上问题，在 `GANs` 中得到了有效的解决。

## `GANs` 与其他模型的对比

此外，与其他结构相比，`GANs` 具有以下优势：

- `GANs` 可以比完全显式的信念网络（`NADE, PixelRNN, WaveNet` 等）更快地产生样本,因为它不需要在采样序列生成不同的数据
- 相比于变分自编码器，`GANs` 没有引入任何决定性偏置（`deterministic bias`），变分方法引入决定性偏置,因为他们优化对数似然的下界,而不是似然度本身,这看起来导致了 `VAEs` 生成的实例比 `GANs` 更模糊.
- 相比非线性 `ICA`（`NICE, Real NVE` 等），`GANs` 不要求生成器输入的潜在变量有任何特定的维度或者要求生成器是可逆的.
- 相比玻尔兹曼机和 `GSNs`，`GANs` 生成实例的过程只需要模型运行一次，而不是以马尔科夫链的形式迭代很多次

# GANs 如何工作

## GANs 的框架

`GAN` 的基本思想是，生成网络和判别网络之间的博弈，如下所示，详细见笔记《`Generative Adversarial Nets`》。

<div style="text-align:center">
<img src="/images/GANs 框架思路.png" width="80%"/>
<p>GANs 框架思路</p>
</div><br>

正式的讲，`GAN` 为结构化概率模型，包含隐含变量 `z` 和观察变量 `x`。

游戏双方通过两个函数进行表示，其对各自的输入和参数均可微。判别器定义为 `D`，以 `x` 为输入，并以 $$\theta^{(D)}$$ 为参数。生成器定义为 `G`，其以 `z` 为输入，并使用 $$\theta^{(G)}$$ 为参数。

此外，各自均有以各自参数进行定义的损失函数。判别器期望最小化 $$J^{(D)}\left(\boldsymbol{\theta}^{(D)}, \boldsymbol{\theta}^{(G)}\right)$$，且必须仅控制参数 $$\theta^{(D)}$$。生成器期望最小化 $$J^{(D)}\left(\boldsymbol{\theta}^{(D)}, \boldsymbol{\theta}^{(G)}\right)$$，且必须仅控制参数 $$\theta^{(G)}$$。

由于双方均由对方的参数决定，且只能控制自己的参数，因此训练优化更像是一个游戏，而非优化，其达到纳什均衡的时候，取得最优解。此时，`G` 和 `D` 达到各自最优解。

## 代价函数

在 `GAN` 框架下，可以使用多种不同的损失函数。

### 判别器的损失函数 $$J^{(D)}$$

大量 `GAN` 的变种在判别器上，使用的代价函数是一样的：

$$
J^{(D)}\left(\boldsymbol{\theta}^{(D)}, \boldsymbol{\theta}^{(G)}\right)=-\frac{1}{2} \mathbb{E}_{\boldsymbol{x} \sim p_{\text { data }}} \log D(\boldsymbol{x})-\frac{1}{2} \mathbb{E}_{\boldsymbol{z}} \log (1-D(G(z)))
$$

上式实际上就是标准交叉熵损失函数，与标准二分类器无差。唯一区别在于，分类器是在两个不同的 `mini-batch` 数据上进行训练的，其中一个来自数据集，`label` 为 `1`；另一个来自生成器，标签为 `0`。

所有版本的 `GAN` 中的判别器，均旨在最小化上式，其优化策略均相同。通过训练判别器，在每一个输入 `x` 上，获取一个估值 $$\frac{p_{\text { data }}(\boldsymbol{x})}{p_{\text { model }}(\boldsymbol{x})}$$。对该值进行估计，将使得我们可以计算各种各样的导数及其梯度。这是使得 `GANs` 区别于变分自编码器和玻尔兹曼机的关键近似技术。

其他深度生成模型基于低边界或马尔科夫链做出近似，而 `GANs` 基于使用监督学习来评估两个数据分布密度之间的比值，从而做出近似。因此 `GANs` 面临着过拟合和欠拟合的风险。但是，使用良好的优化和足够的训练数据，将能克服这些缺陷。

### Minimax

到目前为止，我们只为判别器指定了代价函数。但是，我们仍需要为生成器指定代价函数。其中，最简单的版本就是使用零和游戏，此时：$$J^{(G)}=-J^{(D)}$$。

零和游戏又称为 `minmax` 游戏，因为其形式如下：

$$
\boldsymbol{\theta}^{(G) *}=arg\underset{\boldsymbol{\theta}^{(G)}}\min \underset{\boldsymbol{\theta}^{(D)}}\max V\left(\boldsymbol{\theta}^{(D)}, \boldsymbol{\theta}^{(G)}\right)
$$

### 启发式，非饱和游戏

尽管上面的零和游戏模式下，生成器的损失函数易于理论分析，但实际应用中，其表现并不如意。

最小化目标类别和预测分部之间的交叉熵是高效的，因为当分类器存在误输出时，损失永远不会饱和。而在 `minmax` 游戏中，判别器最小化交叉熵，而生成器最大化同一交叉熵。这对于生成器而言，并不是很好。因为当判别器以高置信度拒绝生成器的输出样本时，生成器的梯度将会消失（无流传回来的梯度）。

为了解决这一问题，一种方式是对生成器继续最小化交叉熵。而对于判别器，我们不再只是简单的反转符号，而是翻转用于创建交叉熵损失的 `target`。因此，生成器的损失变为：

$$
J^{(G)} = -\frac{1}{2}\mathbb{E}_zlogD(G(z))
$$

在该 `minmax` 游戏中，生成器最小化判别器正确分类的对数概率。而这里，生成器最大化判别器判别器犯错的对数概率。这个版本的游戏是启发式动机的，而不是由理论动机的。唯一的动机是保证每一个玩家在失去平衡时，具有较强的梯度。

因此，在这个版本中，游戏不再是零和博弈，因此不能再用一个单一的值函数进行表示。

### 最大似然游戏

我们可能希望使用 `GANs` 来进行极大似然估计的学习，这意味着最小化数据和模型之间的 `KL` 散度。

已有大量的方式来在 `GANs` 框架下，近似公式四，如：

$$
J^{(G)} = -\frac{1}{2} \mathbb{E}_zexp(\sigma^{-1}(D(G(z))))
$$

其中，$$\sigma$$ 为逻辑 `sigmoid` 函数。在判别器最优的情况下，上式与最小化公式四相当。实际上，无论是 `KL` 散度还是 `GAN` 训练进程中的随机梯度下降，相较于真实的梯度，均有一定方差，因为其采用的是样本采样的方式来构建评估梯度。

### 散度的选择是否会影响 GANs

此前有人认为 `GANs` 生成锐化的，真实的样本，是因为其最小化 `JS` 散度；而 `VAE` 使用的是 `KL` 散度，因此生成的样本较为模糊。

`KL` 散度是非对称的，因此最小化 $$D_{KL}(p_{data} || p_{model})$$ 与最小化 $$D_{KL}(p_{model} || p_{data})$$ 是不同的。最大似然估计使用的是前者；而最小化 `JS` 散度更像后者。

如下图所示，后者可能会生成更好的样本，因为用该散度训练的模型更倾向于生成只包含训练分布中出现的模式的样本，即使是其意味着忽略某些其他模式，而不是选择包含所有的模式，但生成某些包含训练数据中未出现的模式样本。

<div style="text-align:center">
<img src="/images/对数似然估计和 KL 散度.png" width="81%"/>
<p>对数似然估计和 KL 散度</p>
</div><br>

如上所示，两种 `KL` 散度并不等效，尤其是模型容量太小，不足以拟合数据分布时，区别尤为明显。这里我们以一维数据为例。使用混合二维高斯分布作为数据分布，一维数据分布作为模型分布。由于一维高斯分布不能拟合二维混合高斯分布，因此散度的选择将会决定模型所做出的折中。

左边的图中，我们使用极大似然估计。此时模型选择拟合两种模式的均值，因此其将输出概率密度高的部分置于两种模式之间。而右边的图中，我们使用反序的 `KL` 散度，此时模型选择仅拟合一种模式。

我们来看 `reverse KL`，在什么时候它取值会很大？就是真实数据不存在的时候，也就是 `G` 产生不像真实数据时，就会产生很大的 `loss`，这时候它不会冒险产生新图，它宁愿保守的产生固有的某个图 (`Mode`) !

综上所述，$$D_{KL}(p_{data} || p_{model})$$ 倾向于将高概率放置于任何可能出现数据的地方；而 $$D_{KL}(p_{model} || p_{data})$$ 更倾向于将低概率放置于任何数据不会出现的地方。从这一点上来看，我们可能期望使用 $$D_{KL}(p_{model} || p_{data})$$ 来生成视觉上表现更好的样本。

一些新的证据表明，使用 `JS` 散度并不能解释为何 `GANs` 能够生成更加锐化的样本：

- 可以使用极大似然估计来训练  `GANs`，此时模型仍旧能生成锐化的样本，仅选择部分模式。
- `GANs` 往往从非常稀少的模式中选择生成样本，相较于模型容量所限制的更少。而反向 `KL` 散度则倾向于从尽可能多的模式中生成样本。这表明，模式坍塌不是因为散度的选择导致的。

总的来说，这表明，由于训练进程的不足，而非要最小化的散度的选择， `GANs` 选择生成小数量的模式。至于 `GANs` 为何生成锐化的图形，原因尚不十分明确。

### 损失函数的对比

我们可以将生成器网络的学习，视作是一种特殊的强化学习。生成器不是为每一个输入 `z` 指定一个输出 `x`，而是采取行动获取输出，并据此获取对应的回报。尤其需要注意，$$J^{(G)}$$ 并不直接参考训练数据，所有关于训练数据的信息均来于判别器的学习。

该进程与传统强化学习还是有所区别，因为：

- 生成器模型不仅能够观察奖励函数的输出，还能够观察到其梯度
- 奖励函数是非饱和的，奖励基于判别器，而判别器根据生成器的变化进行学习

生成器的损失函数在 $$D(G(z))$$ 上，通常是单调递减的，可以设计不同的游戏，来使得损失在曲线的不同部分，减小的更快。

如下图所示，损失响应曲线是 $$D(G(z))$$ 的函数，其包含三种 `GANs` 游戏的变种。我们可以看到，极大似然估计下，损失具有较大的方差，大多数的梯度源自少量的样本 `z`，对应的样本极大可能来自于真实数据。而非饱和设计的损失的样本方差较小，这就可以解释为何其实际应用中更为成功。这表明，减小方差的相关技术将是一个改善 `GANs` 性能的重要的研究领域，尤其是对于基于极大似然而言的 `GANs`。

<div style="text-align:center">
<img src="/images/生成器的损失回报.png" width="85%"/>
<p>生成器的损失回报</p>
</div><br>

## DCGAN 架构

现今大多数的 `GANs` 网络都一定程度基于 `DCGAN` 架构，即深度卷积 `GAN`，其关键点在于：

1. 同时在生成器和判别器的大多数网络层使用 `batch normalization`。并且对于判别器而言，两类样本分别形成一个 `minibatch`，并各自进行归一化。生成器的最后一层和判别器的第一层不进行 `batch normalized`，从而使得模型能够习得数据分布的准确均值和范围。
2. 整个网络结构主要借鉴全卷积网络，其不包含池化层以及上采样层，并分别用卷积层和转置卷积层进行替换。
3. 模型使用 `Adam` 优化器，而非带动量的 `SGD` 优化器

<div style="text-align:center">
<img src="/images/DCGAN.png" width="95%"/>
<p>DCGAN</p>
</div><br>

`DCGAN` 是第一个一段式生成高分辨率图像的 `GAN` 模型，其同时表明，`GAN` 能够学习到以一种有意义的方式，使用隐含编码，就如同简单的算术运算一样，如下所示。

<div style="text-align:center">
<img src="/images/DCGAN 实例.png" width="90%"/>
<p>DCGAN 实例</p>
</div><br>

## GAN 与噪声对比估计和极大似然相似的关系

当我们试图理解 `GAN` 的工作原理的同时，我们可能很自然的会想到，其与噪声对比估计 `NCE`（`noise-constrastive estimation`）的联系。`minmax` 形式的 `GAN` 使用来自 `NCE` 的代价函数作为其值函数，因此一眼看去，两者似乎是一样的。

但实际上，两者学习的东西完全不同，因为两者在游戏中，关注的玩家不同。通俗来讲，`NCE` 的目标是在判别器内学习概率密度模型，而 `GANs` 的目标是定义一个生成器来学习一个采样器。虽然两者在一定程度上相似，但是其训练中的梯度是完全不同的。

更值得注意的是，极大似然估计与 `NCE` 联系较大，相应的，其使用相同的值函数来执行 `minmax` 游戏，但是使用一种启发式的更新策略，而非梯度下降更新策略。

`minmax GANs`、`NCE` 和极大似然估计之间的关联如下所示：

<div style="text-align:center">
<img src="/images/集中模型之间的联系.png" width="90%"/>
<p>集中模型之间的联系</p>
</div><br>

如上表所示，三者均可解释为使用同一值函数，执行 `minmax` 游戏的策略。其最大的区别在于 $$p_{model}$$ 的不同。对于 `GANs` 而言，其生成器为 $$p_{model}$$，而对于 `NCE` 和 `MLE` 而言，$$p_{model}$$ 为判别器的一部分。

除此之外，另一个区别在于更新策略的不同。`GANs` 使用 `SGD` 同时学习两个模型；`MLE` 使用梯度下降学习判别器，而使用启发式更新规则学习生成器。尤其是在每一次更新判别器之后，`MLE` 将会复制判别器内学习到的概率模型，然后将其进行转换为一个采样器，并以此作为生成器。`NCE` 则从不更新生成器，其生成器仅仅是一个固定噪声源。

# 意见和技巧

从业者使用某些技巧来改善 `GANs` 的性能。这些技巧可能并不一定高效，可能某些场景下适用，但是某些时候效果更糟。因此，应该只是将其视为可尝试的点，而不是准则。

## 使用 label 进行训练

以一定形式，使用 `label` 进行训练，可以显著改善模型生成样本在主观感受上的质量，即：在我们期望的方向上得到改善。

该策略为何会奏效，并不完全清晰明了。可能是由于类别信息的辅助，给予训练过程一些有用的线索以指导优化。也可能是因为策略并未真正改善样本的生成质量，只是使得样本朝着我们人类视觉系统所感兴趣的方向进行偏移。如果是因为后者，则该策略并未导致更好的生成模型，来模拟真实的数据分布，但是其仍旧对人类是有用的。

## 单边平滑 label

当判别器评估两个概率密度的比值时， `GANs` 才会工作。但是，当深度神经网络识别出正确的类别时，其易于生成高置信度的输出，对应的概率极高。

为了促使判别器处理分类任务时，评估软概率（`soft probabilities`），而非置信度极高的推断，我们可以使用 `one-sided label smoothing` 技术。其基本思想是将真实图像的 `target` 替换成一个略小于 `1` 的值，例如 `0.9`。

这种方式将避免判别器的极端推断行为：若对于某些输入，其预测的值极大，接近于 `1`，其将被惩罚，并拉回到略小的值。

有一点很重要：不要对 `fake` 样本进行该处理！假设我们使用 $$1 - \alpha$$ 作为真实样本的 `target`；以 $$0 + \beta$$ 作为假样本的 `target`。那么，最优的解释器函数将变为：

$$
D^*(x) = \frac{(1 - \alpha)p_{data}(x) + \beta p_{model}(x)}{p_{data}(x) + p_{model}(x)}
$$

当 $$\beta = 0$$ 时，通过 $$\alpha$$ 进行的 `smooth` 只会减小判别器的最优值。而 $$\beta \neq 0$$ 时，判别器的最优解的形式就发生了变化。

尤其是在 $$p_{data}(x)$$ 很小，而 $$p_{model}(x)$$ 很大的区域，$$D^*(x)$$ 将在 $$p_{model}(x)$$ 的伪模式处，具有一个峰值。此时，判别器将增强生成器的错误行为；而生成器将被训练成要么生成类似于源数据的样本，或者类似于已生成过的样本。

单边标签平滑化是对以前平滑技术的一个简单的改进。其可以作为一个优秀的正则器，不是因为其鼓励模型选择训练集中不正确的类别，而是减少选择正确类别时的置信度。而其他的正则器，如权值衰减等，则通常在正则系数设置过高时，鼓励一些误分类。

## 虚拟批归一化

`batch normalization` 的主要目的在于，通过重新参数化模型，来改善模型的优化，使其每个特征的均值和方差由单一的均值参数和方差参数所决定，而不是其他复杂的计算，详见相关论文。需要注意的是，`BN` 是网络的一部分，因为其参数是可学习的。

尽管 `BN` 很有用，但是在 `GANs` 中，其具有一些副作用。考虑一下，在 `GAN` 中，真实图像和生成的图像，分别需要对应于不同的 `mini-batch`。因此，使用 `BN` 的话，由于不同批次的数据分布的不同，可能导致 `BN` 层相关参数的波动，尤其是当 `batch` 尺寸较小时，影响更是巨大。

针对这一问题，有人提出了 `Reference batch normalization` 技术来进行解决。引用批量归一化主要是运行网络两次：一次是在 `reference examples` 上进行，这些样本在训练开始时刻进行采样，且不会发生更改；另一次是在当前待训练的 `batch` 上运行。

每个特征的均值和标准差使用 `reference batch` 进行计算，随后当前训练的 `batch` 使用这些统计量进行归一化。`reference batch normalization` 的缺点在于，模型可能会对所参考的 `batch` 发生过拟合。

为了解决这一问题，我们可以使用 `virtual batch normalization` 技术，其中每个样本归一化所对应的均值和方差，是通过该样本与参考 `batch` 进行联合计算所得的。

## G 和 D 能否达到平衡？

对于 `GAN` 而言，我们可能会想到，是否需要以某种方式平衡游戏中的两者，避免其中某一方产生绝对的优势。是否这种平衡是必须的，这一点并未有任何的声明。

在作者的描述中，其认为 `GAN` 通过评估数据密度和模型密度的比值来进行工作。仅当判别器是最优的时候，该比值的估算才是准确的，因此判别器略胜于生成器是可行的。

有时候，当判别器置信度很高时，生成器的梯度将会很大。要解决这一问题，要做的不是是的判别器不那么精确，更好的办法是使用 `one-side label smoothing` 技术来进行解决。

此外，要取得最佳的概率密度比，需要判别器始终保持最优，而这又需要训练判别器的时候，迭代步数 `k > 1`，即：每训练判别器 `k` 次后，再训练一次生成器。事实上，这么做并不总是取得明显的改善。

除此之外，我们还可以尝试通过选择合适的模型尺寸来平衡生成器和判别器。实际上，判别器通常比生成器的规模要大。可能是因为判别器需要更高的精度来保证概率密度比值的精确性，但也可能是一种解决 `GAN` 模型坍塌的人为手段，因为生成器通常不会使用其全部的模型容量 —— 从业者并未从增加生成器的尺寸中获取任何收益。因此，若 `GANs` 的模型坍塌问题能够解决，生成器的尺寸将会显著增加，但是判别器的尺寸则不一定。

# 前沿研究

## 不收敛

`GAN` 最大的问题是，模型不收敛的问题。

大多数的深度模型使用优化算法进行训练，这些算法寻找代价函数的最小值。尽管许多问题可能会终止优化，但是优化算法通常会取得较为可靠的下坡进程（代价函数减小）。

`GAN` 需要找寻博弈游戏的纳什均衡。尽管在训练过程中，可能某一个模型沿着下降的趋势进行优化，但同时，另一个模型可能沿着上升的趋势进行反向优化。尽管有时候，两者能够达到纳什均衡，但是更多的时候，在博弈之间，两者是始终不能停留于有用的位置。这是 `GANs` 训练过程中，最常见的问题。因此，若存在通用的解决方法，则 `GAN` 将会得到广泛的应用。

当前，`GANs` 不收敛问题所带来的最严重的问题，可能就是模式坍塌（`mode collapse`）了。

### 模式坍塌

模式坍塌指的是，生成器将多个输入 `z` ，全部映射成同一个输出样本 `x`。实际上，完全的模式坍塌很少见，但是局部模式坍塌则很常见。局部模式坍塌指的是，生成器生成的多个样本，包含相同的颜色或纹理主题，或者同一事物的不同视角。

如下图所示，为模式坍塌的示例，生成器在训练过程中，只会生成 `target` 的一种模式。

<div style="text-align:center">
<img src="/images/模式坍塌.png" width="95%"/>
<p>模式坍塌</p>
</div><br>

模式坍塌的出现，可能是因为 `GAN` 游戏的 `maximin` 的解决方案，与 `minimax` 解决方案是不同的。对于生成模型：

$$
G^* = \min_G \max_D V(G,D)
$$

其中，$$G^*$$ 从数据分布中提取样本。当我们交换 `min` 和 `max` 的顺序时，我们发现：

$$
G^* = \max_D \min_G V(G,D)
$$

此时，对生成器的最小化处于优化进程的内循环中。此时，生成器将要求将每一个 `z` 映射到单一的 `x`，使得判别器极大可能认为该 `x` 为真实样本。而随后进行的梯度下降过程，并不会清晰的偏袒 `minmax` 或 `maxmin`。我们使用 `GANs` 的时候，希望其表现为 `minmax`，但事实上，其通常表现为 `maxmin`。

模式坍塌问题，严重限制了 `GAN` 的应用，将其限制于无需生成丰富样本的一些应用中。

## 生成模型的评估

另一个与 `GAN` 相关的，重要的研究领域是，不知道如何去评估生成模型的质量。一些有着很好的极大似然估计的模型能生成很差的样本，而一些能生成很好样本的模型，可能具有较差的似然。

## 离散化输出

`GANs` 的组成网络必须是可微的。因此，这意味着生成器不能生成离散的数据，例如 `one-hot` 编码等。如何移除该限制，也是 `GANs` 的一大热门研究领域，其可能会导致 `NLP` 领域的发展。可以尝试如下方式：

1. 使用强化学习算法
2. 使用 `Gumbel-softmax` 或 `Gumbel-softmax`
3. 训练生成器，使之生成连续的值，但是这些值可以被编码成离散值

## 半监督学习

在 `GANs` 的相关研究中，存在一个已经较为成功的课题，就是半监督学习（`semi-supervised learning`）。使用特征匹配（`feature matching`）的 `GANs` 来进行半监督学习的基本思路是，将一个 `n` 分类的问题，变换成一个 `n+1` 分类的问题，其中多出的一个维度为 `GANs` 生成的伪样本。

所有的真实样本的概率进行相加，作为 `GAN` 游戏中的判别器，其与训练过程不变。