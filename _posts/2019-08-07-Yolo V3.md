---
layout: post
title:  "Yolo V3 论文笔记"
date:   2019-08-07 15:48:01 +0800
categories: 人工智能
tag: 目标检测
---


* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**

****

**参考**

- [YOLOv3: An Incremental Improvement](<https://pjreddie.com/media/files/papers/YOLOv3.pdf>)
- [HomePage](<https://pjreddie.com/darknet/yolo/>)
- [Github](<https://github.com/BobLiu20/YOLOv3_PyTorch>)

****

# 概述

## `Yolo V3` 的主要工作 

`Yolo V3` 是针对 `Yolo V2` 进行了一些小的优化：主要是在网络结构上进行的优化。最后，`Yolo V3` 在小目标的识别上改善较大，但是中等目标和大目标的识别方面，表现略微下降。

## `Yolo V3` 的整体结构概览

`Yolo V3` 的整体结构如下所示：

<div style="text-align:center">
<img src="/images/Yolo V3 网络结构.jpeg" width="98%">
</div><br>

<div style="text-align:center">
<img src="/images/Yolo V3 具体网络层.png" width="98%">
</div><br>

# 主要改进

## Bounding Box 的预测

在 `Yolo V3` 中，对于每一个 `bounding box` ，网络使用逻辑回归来预测 `objectness` 得分（包含目标的可能性）。

在将每个格点的预选框与 `ground truth` 进行对应，创建 `targets` 时，对于每个 `ground truth`，只对应一个 `bounding box prior`。如果一个 `bounding box prior` 并未对应到某个 `ground truth`，那么它将不计算坐标或类别的 `loss`，只计算 `objectness` 的 `loss`。

## Class Prediction

每一个 `box` 预测的类别可能包含多 `label`，因此我们不使用 `softmax` 激活函数，因为实验表明，效果不好。因此我们使用 `independent logistic classifiers`。

在训练阶段，对于类别预测部分，使用 `binary cross-entropy loss` 。

这种策略便于移植到更复杂的数据集，比如说 `Open Images Dataset`。在该数据集上，存在大量的非独立的 `label`，比方说 `Woman` 和 `Person`。

 ## Predictions Across Scales

`Yolo V3` 在 3 个不同的 `scales` 上进行预测。

在 `COCO` 数据集上，每个 `scale` 的每个格点单元上，预测 3 个 `bounding box`，因此输出 `tensor` 尺寸为：$$N \times N \times [3 * (4 + 1 + 80)] $$。表示 4 个 `bounding box` 坐标，1 个 `objectness` 值，以及 80 个 `class prediction` 值。

### 多尺度融合

首先来看多尺度融合。参考上面的网络结构，将后面的特征图进行 `upsample`，并与前面的特征图进行 `concatenate`，从而融合多种尺度上的特征。这种方式使得我们可以从上采样层获取更多有意义的语义信息 (`semantic information `)，同时从之前的较高分辨率的特征图获取高分辨率的信息。因此，我们的算法可以识别同一张图像中不同大小尺寸的目标。

### 多尺度预测

经过多次度融合，最终得到 3 个尺寸的特征图，如下所示：

<div style="text-align:center">
<img src="/images/多尺寸特征图.jpg" width="60%">
</div><br>

通过在不同尺度上进行预测，可以同时兼顾大小尺寸的目标。比如说在 `13 * 13` 上，粒度较大，适合学习大目标；而在 `52 * 52` 上，粒度较小，同时可以学习小目标。

### NMS

在每个尺寸的特征图上，预测 3 个 `bounding box`，最后进行汇总，可以得到 $$ 13 \times 13 \times 3+ 26 \times 26 \times 3 + 52 \times 52 \times  3 = 10647 $$ 个预测框，其中有很多是不包含目标的，也有很多重复的预测框。

因此，需要使用 `NMS` 来删选得出最终的预测结果。首先排除置信度值较低的预测框，然后使用非极大抑制，排除掉重叠度较高的目标预测框。

### 先验框的选择

同样的，使用 `k-means` 聚类算法来自动提取 `bounding box prior`。最后对其进行排序，并分配到不同的尺度上。`bounding box prior` 如下所示：

```
(10×13),(16×30),(33×23),(30×61),(62×45),(59×119),(116 × 90),(156 × 198),(373 × 326)
```

## Feature Extractor

在 `Yolo V3` 中，使用了新的网络作为基础网络，来进行特征提取。网络使用连续的 $$3 \times 3$$ 和 $$1 \times 1$$ 的卷积层，并引入残差块，因此最后的网络更大，有 53 层卷积层，因此称之为 `Darknet-53`，如下所示：

<div style="text-align:center">
<img src="/images/Darknet-53.png" width="80%">
</div><br>

如上图所示，为 `darknet-53` 网络，用于特征提取。其中，`8x` 表示重复 8 次。

新的网络结构相较于 `Darknet-19` 更强大，但是计算量仍较小。相关比较如下所示：

<div style="text-align:center">
<img src="/images/Darknet-53 性能比较.png" width="90%">
</div><br>

上表中，每个网络的训练设置相同，并在 $$256 \times 256$$ 的输入尺寸上进行测试的。

# 实验

## 训练

我们使用完整的 `images` 进行训练，且未使用 `hard negative mining` 等手段。我们使用 `multi-scale` 训练，大量的数据增强，`batch normalization` 等等。

## 实验表现

`YOLO V3` 在 `mAP` 指标上表现卓越。然而，当调高 `IOU` 数值时，性能急剧下降。

各种模型的实验性能对比如下所示：

<div style="text-align:center">
<img src="/images/各种实施模型性能对比.png" width="90%">
</div><br>

`YOLO` 早期版本中，网络难于检测小目标。但是现在，使用多尺度方式之后，性能大大提升，可以较好的检测小目标。然而，对于中等或较大目标反而较难检测。因此，后续需要更多的研究。

<div style="text-align:center">
<img src="/images/Yolo V3 实验结果.png" width="98%">
</div><br>

<div style="text-align:center">
<img src="/images/Yolo V3 实验结果 2.png" width="98%">
</div><br>