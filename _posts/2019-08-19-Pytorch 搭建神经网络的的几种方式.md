---
layout: post
title:  "Pytorch 搭建神经网络的的几种方式"
date:   2019-08-19 18:07:01 +0800
categories: 人工智能
tag: Pytorch
---

* content
{:toc}


****

> **未经许可，严禁任何形式的转载！**

****

## 引入

利用 `Pytorch` 构建神经网络模型的方法有多种，现假设构建如下模型：

> 卷积层 —> Relu层 —> 池化层 —> 全连接层 —> Relu层 —> 全连接层

首先导入几种方法用到的包：

```python
import torch
import torch.nn.functional as F
from collections import OrderedDict
```

## 直接搭建

可以直接按顺序逐层搭建，如下所示：

```python
class Net1(torch.nn.Module):
    def __init__(self):
        super(Net1, self).__init__()
        self.conv1 = torch.nn.Conv2d(3, 32, 3, 1, 1)
        self.dense1 = torch.nn.Linear(32 * 3 * 3, 128)
        self.dense2 = torch.nn.Linear(128, 10)
 
    def forward(self, x):
        x = F.max_pool2d(F.relu(self.conv(x)), 2)
        x = x.view(x.size(0), -1)
        x = F.relu(self.dense1(x))
        x = self.dense2(x)
        return x
 
print("Method 1:")
model1 = Net1()
print(model1)
```

结果如下所示：

```python
Net1(
  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (dense1): Linear(in_features=288, out_features=128, bias=True)
  (dense2): Linear(in_features=128, out_features=10, bias=True)
)
```

## 通过 Sequential 搭建

还可以利用 **Sequential** 搭建 **block**，然后利用 `block` 搭建完整的网络。如下所示：

```python
class Net2(torch.nn.Module):
    def __init__(self):
        super(Net2, self).__init__()
        self.conv = torch.nn.Sequential(
            torch.nn.Conv2d(3, 32, 3, 1, 1),
            torch.nn.ReLU(),
            torch.nn.MaxPool2d(2))
        self.dense = torch.nn.Sequential(
            torch.nn.Linear(32 * 3 * 3, 128),
            torch.nn.ReLU(),
            torch.nn.Linear(128, 10)
        )
 
    def forward(self, x):
        conv_out = self.conv1(x)
        res = conv_out.view(conv_out.size(0), -1)
        out = self.dense(res)
        return out
 
print("Method 2:")
model2 = Net2()
print(model2)
```

这种方法利用 **torch.nn.Sequential()** 容器进行快速搭建，模型的各层被**顺序添加**到容器中。缺点是每层的编号是默认的阿拉伯数字，结果如下所示：结果如下所示：

```python
Net2(
  (conv): Sequential(
    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU()
    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (dense): Sequential(
    (0): Linear(in_features=288, out_features=128, bias=True)
    (1): ReLU()
    (2): Linear(in_features=128, out_features=10, bias=True)
  )
)
```

## 通过 add_module 搭建

可以使用 **add_module** 搭建网络，该方法是基于 **torch.nn.Sequential()** 的，但是相比于之下，可以自定义各层的名称。如下所示：

```python
class Net3(torch.nn.Module):
    def __init__(self):
        super(Net3, self).__init__()
        self.conv=torch.nn.Sequential()
        self.conv.add_module("conv1", torch.nn.Conv2d(3, 32, 3, 1, 1))
        self.conv.add_module("relu1", torch.nn.ReLU())
        self.conv.add_module("pool1", torch.nn.MaxPool2d(2))
        
        self.dense = torch.nn.Sequential()
        self.dense.add_module("dense1", torch.nn.Linear(32 * 3 * 3, 128))
        self.dense.add_module("relu2", torch.nn.ReLU())
        self.dense.add_module("dense2", torch.nn.Linear(128, 10))
 
    def forward(self, x):
        conv_out = self.conv1(x)
        res = conv_out.view(conv_out.size(0), -1)
        out = self.dense(res)
        return out
 
print("Method 3:")
model3 = Net3()
print(model3)
```

结果如下所示：

```python
Net3(
  (conv): Sequential(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu1): ReLU()
    (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (dense): Sequential(
    (dense1): Linear(in_features=288, out_features=128, bias=True)
    (relu2): ReLU()
    (dense2): Linear(in_features=128, out_features=10, bias=True)
  )
)
```

## 通过 OrderedDict 创建

还可以通过 **OrderedDict** 来给 **torch.nn.Sequential()** 中的每一层进行命名。如下所示：

```python
class Net4(torch.nn.Module):
    def __init__(self):
        super(Net4, self).__init__()
        self.conv = torch.nn.Sequential(
            OrderedDict(
                [
                    ("conv1", torch.nn.Conv2d(3, 32, 3, 1, 1)),
                    ("relu1", torch.nn.ReLU()),
                    ("pool", torch.nn.MaxPool2d(2))
                ]
            ))
 
        self.dense = torch.nn.Sequential(
            OrderedDict([
                ("dense1", torch.nn.Linear(32 * 3 * 3, 128)),
                ("relu2", torch.nn.ReLU()),
                ("dense2", torch.nn.Linear(128, 10))
            ])
        )
 
    def forward(self, x):
        conv_out = self.conv1(x)
        res = conv_out.view(conv_out.size(0), -1)
        out = self.dense(res)
        return out
 
print("Method 4:")
model4 = Net4()
print(model4)
```

结果如下所示：

```python
Net4(
  (conv): Sequential(
    (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (relu1): ReLU()
    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (dense): Sequential(
    (dense1): Linear(in_features=288, out_features=128, bias=True)
    (relu2): ReLU()
    (dense2): Linear(in_features=128, out_features=10, bias=True)
  )
)
```

## 通过 nn.ModuleList 创建

**ModuleList** 也是一个特殊的 `module`，可以包含几个子 `module`，可以像用 `list` 一样使用它，但不能直接把输入传给 `ModuleList`。如下所示：

```python
modellist = nn.ModuleList([nn.Linear(3,4), nn.ReLU(), nn.Linear(4,2)])

input = t.randn(1, 3)

for model in modellist:
    input = model(input)

# 下面会报错,因为modellist没有实现forward方法
# output = modelist(input)
```

因为 `ModuleList` 是 **Module** 的子类，当在 `Module` 中使用它的时候，就能自动识别为子 `module`。

## 动态创建神经网络

```python
import torch
import random
from torch.autograd import Variable
 
class DynamicNet(torch.nn.Module):
    def __init__(self, D_in, H, D_out):
        super(DynamicNet, self).__init__()
        
        self.input_linear = torch.nn.Linear(D_in, H)
        self.middle_linear = torch.nn.Linear(H,H)
        self.output_linear = torch.nn.Linear(H,D_out)
 
    def forward(self, x):
        h_relu = self.input_linear(x).clamp(min=0)
      
        for _ in range(random.randint(0,3)):
            h_relu = self.middle_linear(h_relu).clamp(min=0)
            
        y_pred = self.output_linear(h_relu)
        return y_pred
```